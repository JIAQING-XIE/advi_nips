
    
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<meta http-equiv="X-UA-Compatible" content="IE=7" />
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="author" content="Turnitin, LLC" />
    <meta name="keywords" content="" /> 
    <meta name="description" content="" />
    <meta name="viewport" content="width = initial-scale" />
    <meta name="viewport" content="height = initial-scale" />
    
<title>Turnitin Originality Report</title>

<style type="text/css" media="screen">
#actions {
	display: block;
	width: 100%;
	text-align: center;
	border-bottom: 1px solid #888;
	padding: 20px 0px 30px;
	background: #eee;
	}
	
#actions a	{
	color: #00f;
	}

#actions p	{
	text-align: center;
	}
	
</style>

<link rel="stylesheet" type="text/css" href="https://www.turnitinuk.com/r/build/css/tii/972ffd2859ac15b72890fc369e9e71fecb_newreport_styles_print.css" media="all" />




</head>

<body id="or_print_report">






<div id="top">
    <div id="content">
        <!-- ######### Top Body  ##########################--> 
        <div id="top_body">
            <p id="title">
            <img src="https://www.turnitinuk.com/r/build/images/b3964fd7e38c8fcbb8bfbf2efc1f0635cb_turnitin_logo.gif" id="logo" width="60">
            Turnitin Originality Report
            </p>
                <div class="general_info">
                    <p>
                        <span>improved autoguides for probabilistic programs</span>
                        
                        by NoJiaqing Xie
                        
                    </p>
                    <p>
                        From 123 (Economic management)
                    </p>
                    <ul>
                        <li>Processed on 07-Apr-2022 09:31 CST</li>
                        <li>ID: 1803865636</li>
                        <li>Word Count: 18844</li>
                    </ul>
                </div>
                <div class="similarity_box">
                    <div class="overall_similarity">
                        <div class="color_box green">&nbsp;</div>
                        <div class="similarity_title">Similarity Index</div>
                        <div class="similarity_percent">14%</div>
                    </div>
                    <div class="similarity_by_source">
                        <div class="similarity_title">Similarity by Source</div>
                        <dl>
                            <dt>Internet&nbsp;Sources:</dt>
                            <dd>12%</dd>
                            <div class="clear"></div>
                            <dt>Publications:</dt>
                            <dd>11%</dd>
                            <div class="clear"></div>
                            <dt>Student&nbsp;Papers:</dt>
                            <dd>8%</dd>
                            <div class="clear"></div>
                        </dl>
                    </div>
                </div>
                <div class="clear"></div>
                                 
        </div>
        <!-- ######### END Top Body  ##########################--> 
    </div>
</div>

<div class="divider">sources:</div>

<div class="links">

	<div>
	<div class="number-l">1</div>
	<p>< 1% match (Internet from 16-Aug-2018)</p>

	<a style="color:#D10A0A" href="https://arxiv.org/pdf/1606.05908.pdf">https://arxiv.org/pdf/1606.05908.pdf</a>

	</div>
	<div>
	<div class="number-l">2</div>
	<p>< 1% match ()</p>

	<a style="color:#287B28" href="http://arxiv.org/abs/1906.02691">Kingma, Diederik P., Welling, Max. "An Introduction to Variational Autoencoders", 'Now Publishers', 2019</a>

	</div>
	<div>
	<div class="number-l">3</div>
	<p>< 1% match ()</p>

	<a style="color:blue" href="http://arxiv.org/abs/2110.13422">Zadeh, Amir, Benoit, Santiago, Morency, Louis-Philippe. "Relay Variational Inference: A Method for Accelerated Encoderless VI", 2021</a>

	</div>
	<div>
	<div class="number-l">4</div>
	<p>< 1% match ()</p>

	<a style="color:brown" href="http://arxiv.org/abs/2106.13746">Miao, Ning, Mathieu, Emile, Siddharth, N., Teh, Yee Whye, Rainforth, Tom. "InteL-VAEs: Adding Inductive Biases to Variational Auto-Encoders via  Intermediary Latents", 2021</a>

	</div>
	<div>
	<div class="number-l">5</div>
	<p>< 1% match (Internet from 02-Feb-2022)</p>

	<a style="color:#B64B01" href="https://arxiv.org/pdf/2201.12430.pdf">https://arxiv.org/pdf/2201.12430.pdf</a>

	</div>
	<div>
	<div class="number-l">6</div>
	<p>< 1% match ()</p>

	<a style="color:#630000" href="http://arxiv.org/abs/2001.07910">Berger, Victor, Sebag, Michèle. "From abstract items to latent spaces to observed data and back:  Compositional Variational Auto-Encoder", 2020</a>

	</div>
	<div>
	<div class="number-l">7</div>
	<p>< 1% match (Internet from 22-Dec-2021)</p>

	<a style="color:#0270B6" href="https://arxiv.org/pdf/2112.10510.pdf">https://arxiv.org/pdf/2112.10510.pdf</a>

	</div>
	<div>
	<div class="number-l">8</div>
	<p>< 1% match ()</p>

	<a style="color:#330099" href="http://arxiv.org/abs/1910.08091">Perov, Yura, Graham, Logan, Gourgoulias, Kostis, Richens, Jonathan G., Lee, Ciarán M., Baker, Adam, Johri, Saurabh. "MultiVerse: Causal Reasoning using Importance Sampling in Probabilistic  Programming", 2020</a>

	</div>
	<div>
	<div class="number-l">9</div>
	<p>< 1% match (Internet from 18-Mar-2022)</p>

	<a style="color:#227967" href="https://arxiv.org/pdf/2203.08015.pdf">https://arxiv.org/pdf/2203.08015.pdf</a>

	</div>
	<div>
	<div class="number-l">10</div>
	<p>< 1% match ()</p>

	<a style="color:#CB0099" href="http://arxiv.org/abs/2003.00704">Tolpin, David, Zhou, Yuan, Yang, Hongseok. "Stochastically Differentiable Probabilistic Programs", 2020</a>

	</div>
	<div>
	<div class="number-l">11</div>
	<p>< 1% match ()</p>

	<a style="color:#006331" href="http://arxiv.org/abs/2106.00736">Mokrov, Petr, Korotin, Alexander, Li, Lingxiao, Genevay, Aude, Solomon, Justin, Burnaev, Evgeny. "Large-Scale Wasserstein Gradient Flows", 2021</a>

	</div>
	<div>
	<div class="number-l">12</div>
	<p>< 1% match ()</p>

	<a style="color:#795AB9" href="http://arxiv.org/abs/1908.08356">Zhang, Xin, Curtis, Andrew. "Seismic tomography using variational inference methods", 2019</a>

	</div>
	<div>
	<div class="number-l">13</div>
	<p>< 1% match ()</p>

	<a style="color:#935F32" href="http://arxiv.org/abs/2009.06795">Shao, Huajie, Lin, Haohong, Yang, Qinmin, Yao, Shuochao, Zhao, Han, Abdelzaher, Tarek. "DynamicVAE: Decoupling Reconstruction Error and Disentangled  Representation Learning", 2020</a>

	</div>
	<div>
	<div class="number-l">14</div>
	<p>< 1% match (Internet from 12-Feb-2022)</p>

	<a style="color:#ce0031" href="https://arxiv.org/pdf/2202.05063.pdf">https://arxiv.org/pdf/2202.05063.pdf</a>

	</div>
	<div>
	<div class="number-l">15</div>
	<p>< 1% match (Internet from 30-Dec-2021)</p>

	<a style="color:#866712" href="https://arxiv.org/pdf/2112.13548.pdf">https://arxiv.org/pdf/2112.13548.pdf</a>

	</div>
	<div>
	<div class="number-l">16</div>
	<p>< 1% match (Internet from 06-May-2021)</p>

	<a style="color:#63009c" href="https://papers.neurips.cc/paper/2020/file/31784d9fc1fa0d25d04eae50ac9bf787-Paper.pdf">https://papers.neurips.cc/paper/2020/file/31784d9fc1fa0d25d04eae50ac9bf787-Paper.pdf</a>

	</div>
	<div>
	<div class="number-l">17</div>
	<p>< 1% match (Internet from 03-May-2021)</p>

	<a style="color:#A85503" href="https://papers.neurips.cc/paper/2019/file/e721a54a8cf18c8543d44782d9ef681f-Paper.pdf">https://papers.neurips.cc/paper/2019/file/e721a54a8cf18c8543d44782d9ef681f-Paper.pdf</a>

	</div>
	<div>
	<div class="number-l">18</div>
	<p>< 1% match (Internet from 03-May-2021)</p>

	<a style="color:#cc0066" href="https://papers.neurips.cc/paper/2019/file/eea5d933e9dce59c7dd0f6532f9ea81b-Paper.pdf">https://papers.neurips.cc/paper/2019/file/eea5d933e9dce59c7dd0f6532f9ea81b-Paper.pdf</a>

	</div>
	<div>
	<div class="number-l">19</div>
	<p>< 1% match (Internet from 09-Feb-2022)</p>

	<a style="color:#21785B" href="https://papers.neurips.cc/paper/2021/file/05f971b5ec196b8c65b75d2ef8267331-Paper.pdf">https://papers.neurips.cc/paper/2021/file/05f971b5ec196b8c65b75d2ef8267331-Paper.pdf</a>

	</div>
	<div>
	<div class="number-l">20</div>
	<p>< 1% match (Internet from 09-Feb-2022)</p>

	<a style="color:#336699" href="https://papers.neurips.cc/paper/2021/file/37f0e884fbad9667e38940169d0a3c95-Paper.pdf">https://papers.neurips.cc/paper/2021/file/37f0e884fbad9667e38940169d0a3c95-Paper.pdf</a>

	</div>
	<div>
	<div class="number-l">21</div>
	<p>< 1% match (Internet from 10-Feb-2022)</p>

	<a style="color:#D10A0A" href="https://papers.neurips.cc/paper/2021/file/d811406316b669ad3d370d78b51b1d2e-Paper.pdf">https://papers.neurips.cc/paper/2021/file/d811406316b669ad3d370d78b51b1d2e-Paper.pdf</a>

	</div>
	<div>
	<div class="number-l">22</div>
	<p>< 1% match (Internet from 02-May-2021)</p>

	<a style="color:#287B28" href="https://papers.neurips.cc/paper/2019/file/a6197a578fe7778e8d49a95ac425bcfc-Paper.pdf">https://papers.neurips.cc/paper/2019/file/a6197a578fe7778e8d49a95ac425bcfc-Paper.pdf</a>

	</div>
	<div>
	<div class="number-l">23</div>
	<p>< 1% match (Internet from 04-May-2020)</p>

	<a style="color:blue" href="http://export.arxiv.org/pdf/1810.01539">http://export.arxiv.org/pdf/1810.01539</a>

	</div>
	<div>
	<div class="number-l">24</div>
	<p>< 1% match (Internet from 20-Aug-2020)</p>

	<a style="color:brown" href="http://export.arxiv.org/pdf/1812.06834">http://export.arxiv.org/pdf/1812.06834</a>

	</div>
	<div>
	<div class="number-l">25</div>
	<p>< 1% match (Internet from 05-Dec-2018)</p>

	<a style="color:#B64B01" href="http://export.arxiv.org/pdf/1708.06040">http://export.arxiv.org/pdf/1708.06040</a>

	</div>
	<div>
	<div class="number-l">26</div>
	<p>< 1% match (Internet from 30-Jan-2020)</p>

	<a style="color:#630000" href="http://export.arxiv.org/pdf/1912.02762">http://export.arxiv.org/pdf/1912.02762</a>

	</div>
	<div>
	<div class="number-l">27</div>
	<p>< 1% match (Internet from 03-Feb-2020)</p>

	<a style="color:#0270B6" href="http://export.arxiv.org/pdf/2001.04676">http://export.arxiv.org/pdf/2001.04676</a>

	</div>
	<div>
	<div class="number-l">28</div>
	<p>< 1% match (Internet from 09-Oct-2021)</p>

	<a style="color:#330099" href="http://arxiv-export-lb.library.cornell.edu/pdf/2002.00276">http://arxiv-export-lb.library.cornell.edu/pdf/2002.00276</a>

	</div>
	<div>
	<div class="number-l">29</div>
	<p>< 1% match (Internet from 24-Sep-2021)</p>

	<a style="color:#227967" href="http://arxiv-export-lb.library.cornell.edu/pdf/2010.15750">http://arxiv-export-lb.library.cornell.edu/pdf/2010.15750</a>

	</div>
	<div>
	<div class="number-l">30</div>
	<p>< 1% match (Internet from 23-Dec-2021)</p>

	<a style="color:#CB0099" href="https://www.arxiv-vanity.com/papers/1906.02691/">https://www.arxiv-vanity.com/papers/1906.02691/</a>

	</div>
	<div>
	<div class="number-l">31</div>
	<p>< 1% match (Internet from 07-Jan-2022)</p>

	<a style="color:#006331" href="https://www.arxiv-vanity.com/papers/1812.02274/">https://www.arxiv-vanity.com/papers/1812.02274/</a>

	</div>
	<div>
	<div class="number-l">32</div>
	<p>< 1% match (Internet from 24-Dec-2021)</p>

	<a style="color:#795AB9" href="https://www.arxiv-vanity.com/papers/2007.06823/">https://www.arxiv-vanity.com/papers/2007.06823/</a>

	</div>
	<div>
	<div class="number-l">33</div>
	<p>< 1% match (Internet from 23-Dec-2021)</p>

	<a style="color:#935F32" href="https://www.repository.cam.ac.uk/bitstream/handle/1810/331555/thesis.pdf?isAllowed=y&sequence=3">https://www.repository.cam.ac.uk/bitstream/handle/1810/331555/thesis.pdf?isAllowed=y&sequence=3</a>

	</div>
	<div>
	<div class="number-l">34</div>
	<p>< 1% match ()</p>

	<a style="color:#ce0031" href="https://www.repository.cam.ac.uk/handle/1810/303263">Bauer, Matthias. "Advances in Probabilistic Modelling: Sparse Gaussian Processes, Autoencoders, and Few-shot Learning", Pembroke, 2020</a>

	</div>
	<div>
	<div class="number-l">35</div>
	<p>< 1% match (student papers from 09-Sep-2013)</p>

	<a style="color:#866712" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:25838720&n=2&perc=0">Submitted to University of Southampton  on 2013-09-09</a>

	</div>
	<div>
	<div class="number-l">36</div>
	<p>< 1% match (student papers from 23-Jul-2020)</p>

	<a style="color:#63009c" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:1:1804901830&n=1&perc=0">Submitted to Universiteit van Amsterdam on 2020-07-23</a>

	</div>
	<div>
	<div class="number-l">37</div>
	<p>< 1% match (student papers from 12-Jun-2020)</p>

	<a style="color:#A85503" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:1:1784928248&n=1&perc=0">Submitted to Universiteit van Amsterdam on 2020-06-12</a>

	</div>
	<div>
	<div class="number-l">38</div>
	<p>< 1% match (Internet from 21-Jun-2019)</p>

	<a style="color:#cc0066" href="http://mlss2018.net.ar/slides/Wood-1.pdf">http://mlss2018.net.ar/slides/Wood-1.pdf</a>

	</div>
	<div>
	<div class="number-l">39</div>
	<p>< 1% match (Internet from 15-Dec-2021)</p>

	<a style="color:#21785B" href="http://user.it.uu.se/%7Ethosc112/team/naesseth2018phd.pdf">http://user.it.uu.se/%7Ethosc112/team/naesseth2018phd.pdf</a>

	</div>
	<div>
	<div class="number-l">40</div>
	<p>< 1% match (Internet from 27-Jun-2018)</p>

	<a style="color:#336699" href="http://www.jmlr.org/papers/volume18/16-107/16-107.pdf">http://www.jmlr.org/papers/volume18/16-107/16-107.pdf</a>

	</div>
	<div>
	<div class="number-l">41</div>
	<p>< 1% match (Internet from 26-Mar-2020)</p>

	<a style="color:#D10A0A" href="http://www.jmlr.org/papers/volume20/17-452/17-452.pdf">http://www.jmlr.org/papers/volume20/17-452/17-452.pdf</a>

	</div>
	<div>
	<div class="number-l">42</div>
	<p>< 1% match (student papers from 17-Aug-2011)</p>

	<a style="color:#287B28" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:11855509&n=2&perc=0">Submitted to University of Edinburgh  on 2011-08-17</a>

	</div>
	<div>
	<div class="number-l">43</div>
	<p>< 1% match (Internet from 26-Feb-2022)</p>

	<a style="color:blue" href="https://dspace.mit.edu/bitstream/handle/1721.1/129247/1227518338-MIT.pdf?isAllowed=y&sequence=1">https://dspace.mit.edu/bitstream/handle/1721.1/129247/1227518338-MIT.pdf?isAllowed=y&sequence=1</a>

	</div>
	<div>
	<div class="number-l">44</div>
	<p>< 1% match (Internet from 29-Oct-2021)</p>

	<a style="color:brown" href="https://github.com/tts-tutorial/survey">https://github.com/tts-tutorial/survey</a>

	</div>
	<div>
	<div class="number-l">45</div>
	<p>< 1% match ()</p>

	<a style="color:#B64B01" href="http://hdl.handle.net/2434/700444">A.C.A. CHEMLA ROMEU SANTOS. "MANIFOLD REPRESENTATIONS OF MUSICAL SIGNALS AND GENERATIVE SPACES", Università degli Studi di Milano, 2020</a>

	</div>
	<div>
	<div class="number-l">46</div>
	<p>< 1% match ()</p>

	<a style="color:#630000" href="http://hdl.handle.net/10138/325149">Sakaya, Joseph Hosanna. "From Approximations to Decisions", 'University of Helsinki Libraries', 2021</a>

	</div>
	<div>
	<div class="number-l">47</div>
	<p>< 1% match (Kim, Yoon H.. "Deep Latent Variable Models of Natural Language", Harvard University, 2021)</p>

	<a style="color:#0270B6" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28452516">Kim, Yoon H.. "Deep Latent Variable Models of Natural Language", Harvard University, 2021</a>

	</div>
	<div>
	<div class="number-l">48</div>
	<p>< 1% match (student papers from 18-May-2018)</p>

	<a style="color:#330099" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:89494272&n=2&perc=0">Submitted to University of Cambridge  on 2018-05-18</a>

	</div>
	<div>
	<div class="number-l">49</div>
	<p>< 1% match (Internet from 12-Dec-2020)</p>

	<a style="color:#227967" href="https://vibdoc.com/machine-learning-a-probabilistic-perspective.html">https://vibdoc.com/machine-learning-a-probabilistic-perspective.html</a>

	</div>
	<div>
	<div class="number-l">50</div>
	<p>< 1% match (student papers from 13-Dec-2020)</p>

	<a style="color:#CB0099" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:643312618&n=2&perc=0">Submitted to Heriot-Watt University  on 2020-12-13</a>

	</div>
	<div>
	<div class="number-l">51</div>
	<p>< 1% match (student papers from 14-Nov-2021)</p>

	<a style="color:#006331" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:1:2171387143&n=1&perc=0">Submitted to University of New South Wales on 2021-11-14</a>

	</div>
	<div>
	<div class="number-l">52</div>
	<p>< 1% match ()</p>

	<a style="color:#795AB9" href="https://orbi.uliege.be/handle/2268/226859">Gunes Baydin, Atilim, Heinrich, Lukas et al. "Efficient Probabilistic Inference in the Quest for Physics Beyond the Standard Model", 2019</a>

	</div>
	<div>
	<div class="number-l">53</div>
	<p>< 1% match (Internet from 03-Mar-2022)</p>

	<a style="color:#935F32" href="https://thesis.eur.nl/pub/59482/Thesis_MH_21062021.pdf">https://thesis.eur.nl/pub/59482/Thesis_MH_21062021.pdf</a>

	</div>
	<div>
	<div class="number-l">54</div>
	<p>< 1% match (Webb, Jared Anthony. "A Topics Analysis Model for Health Insurance Claims", Brigham Young University, 2021)</p>

	<a style="color:#ce0031" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28112574">Webb, Jared Anthony. "A Topics Analysis Model for Health Insurance Claims", Brigham Young University, 2021</a>

	</div>
	<div>
	<div class="number-l">55</div>
	<p>< 1% match (publications)</p>

	<a style="color:#866712" href="https://doi.org/10.1007/978-3-030-01246-5">"Computer Vision – ECCV 2018", Springer Science and Business Media LLC, 2018</a>

	</div>
	<div>
	<div class="number-l">56</div>
	<p>< 1% match (publications)</p>

	<a style="color:#63009c" href="https://doi.org/10.1007/978-3-030-01228-1">"Computer Vision – ECCV 2018", Springer Science and Business Media LLC, 2018</a>

	</div>
	<div>
	<div class="number-l">57</div>
	<p>< 1% match (publications)</p>

	<a style="color:#A85503" href="https://doi.org/10.1145/3442188.3445912">Jessie Finocchiaro, Roland Maio, Faidra Monachou, Gourab K Patro, Manish Raghavan, Ana-Andreea Stoica, Stratis Tsirtsis. "Bridging Machine Learning and Mechanism Design towards Algorithmic Fairness", Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 2021</a>

	</div>
	<div>
	<div class="number-l">58</div>
	<p>< 1% match (publications)</p>

	<a style="color:#cc0066" href="https://doi.org/10.3233/FAIA325">"ECAI 2020", IOS Press, 2020</a>

	</div>
	<div>
	<div class="number-l">59</div>
	<p>< 1% match (Yoder, David T.. "Storage and Mobility among the Fremont: Changing Forms through Time.", Brigham Young University, 2020)</p>

	<a style="color:#21785B" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28109155">Yoder, David T.. "Storage and Mobility among the Fremont: Changing Forms through Time.", Brigham Young University, 2020</a>

	</div>
	<div>
	<div class="number-l">60</div>
	<p>< 1% match (publications)</p>

	<a style="color:#336699" href="http://link.springer.com/10.1007/978-1-4614-5104-4">Uffe B. Kjærulff, Anders L. Madsen. "Bayesian Networks and Influence Diagrams: A Guide to Construction and Analysis", Springer Nature, 2013</a>

	</div>
	<div>
	<div class="number-l">61</div>
	<p>< 1% match (Internet from 12-May-2020)</p>

	<a style="color:#D10A0A" href="https://escholarship.org/content/qt26m5x35m/qt26m5x35m.pdf?t=ppqqsg">https://escholarship.org/content/qt26m5x35m/qt26m5x35m.pdf?t=ppqqsg</a>

	</div>
	<div>
	<div class="number-l">62</div>
	<p>< 1% match (Internet from 19-Mar-2019)</p>

	<a style="color:#287B28" href="https://repository.tudelft.nl/islandora/object/uuid:faa7cd3f-a946-4685-a36e-d01a15c4159e/datastream/OBJ/download">https://repository.tudelft.nl/islandora/object/uuid:faa7cd3f-a946-4685-a36e-d01a15c4159e/datastream/OBJ/download</a>

	</div>
	<div>
	<div class="number-l">63</div>
	<p>< 1% match (Internet from 03-Jul-2019)</p>

	<a style="color:blue" href="https://repository.tudelft.nl/islandora/object/uuid:659e9fd5-d251-46fe-8455-3a17bdd4f48c/datastream/OBJ/download">https://repository.tudelft.nl/islandora/object/uuid:659e9fd5-d251-46fe-8455-3a17bdd4f48c/datastream/OBJ/download</a>

	</div>
	<div>
	<div class="number-l">64</div>
	<p>< 1% match (Balestriero, Randall. "Max-Affine Splines Insights into Deep Learning", Rice University, 2021)</p>

	<a style="color:brown" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28736027">Balestriero, Randall. "Max-Affine Splines Insights into Deep Learning", Rice University, 2021</a>

	</div>
	<div>
	<div class="number-l">65</div>
	<p>< 1% match (Internet from 11-Feb-2016)</p>

	<a style="color:#B64B01" href="http://media.proquest.com/media/pq/classic/doc/3375666821/fmt/ai/rep/NPDF?_s=f66a7KxiDgprQYXpqPDOZ%2FsJz1I%3D">http://media.proquest.com/media/pq/classic/doc/3375666821/fmt/ai/rep/NPDF?_s=f66a7KxiDgprQYXpqPDOZ%2FsJz1I%3D</a>

	</div>
	<div>
	<div class="number-l">66</div>
	<p>< 1% match (Wu, Anqi. "Bayesian Latent Structure Discovery for Large-Scale Neural Recordings.", Princeton University, 2019)</p>

	<a style="color:#630000" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:22589286">Wu, Anqi. "Bayesian Latent Structure Discovery for Large-Scale Neural Recordings.", Princeton University, 2019</a>

	</div>
	<div>
	<div class="number-l">67</div>
	<p>< 1% match (Internet from 13-Jul-2021)</p>

	<a style="color:#0270B6" href="https://silo.pub/large-sample-techniques-for-statistics-springer-texts-in-statistics.html">https://silo.pub/large-sample-techniques-for-statistics-springer-texts-in-statistics.html</a>

	</div>
	<div>
	<div class="number-l">68</div>
	<p>< 1% match (student papers from 04-May-2017)</p>

	<a style="color:#330099" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:1:809400068&n=1&perc=0">Submitted to Indian Institute of Technology, Bombay on 2017-05-04</a>

	</div>
	<div>
	<div class="number-l">69</div>
	<p>< 1% match (Internet from 19-Nov-2021)</p>

	<a style="color:#227967" href="https://cs.stanford.edu/~ermon/cv.pdf">https://cs.stanford.edu/~ermon/cv.pdf</a>

	</div>
	<div>
	<div class="number-l">70</div>
	<p>< 1% match (Internet from 31-Mar-2010)</p>

	<a style="color:#CB0099" href="http://fuzzy.cs.uni-magdeburg.de/wiki/uploads/Lehre.BN0809/bn.pdf">http://fuzzy.cs.uni-magdeburg.de/wiki/uploads/Lehre.BN0809/bn.pdf</a>

	</div>
	<div>
	<div class="number-l">71</div>
	<p>< 1% match (Internet from 10-Aug-2020)</p>

	<a style="color:#006331" href="https://mafiadoc.com/arxiv150205767v4-cssc-5-feb-2018_5bb81b5d097c4787138b45aa.html">https://mafiadoc.com/arxiv150205767v4-cssc-5-feb-2018_5bb81b5d097c4787138b45aa.html</a>

	</div>
	<div>
	<div class="number-l">72</div>
	<p>< 1% match (Internet from 21-Feb-2022)</p>

	<a style="color:#795AB9" href="https://web.archive.org/web/20200831202459if_/https:/arxiv.org/pdf/1709.05870v1.pdf">https://web.archive.org/web/20200831202459if_/https:/arxiv.org/pdf/1709.05870v1.pdf</a>

	</div>
	<div>
	<div class="number-l">73</div>
	<p>< 1% match (Internet from 20-Nov-2019)</p>

	<a style="color:#935F32" href="https://www.tandfonline.com/doi/full/10.1080/10888691.2016.1270764">https://www.tandfonline.com/doi/full/10.1080/10888691.2016.1270764</a>

	</div>
	<div>
	<div class="number-l">74</div>
	<p>< 1% match (student papers from 27-May-2019)</p>

	<a style="color:#ce0031" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:1:1561983947&n=1&perc=0">Submitted to National Research University Higher School of Economics on 2019-05-27</a>

	</div>
	<div>
	<div class="number-l">75</div>
	<p>< 1% match (student papers from 15-Sep-2017)</p>

	<a style="color:#866712" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:1:845900166&n=1&perc=0">Submitted to University of New York in Tirana on 2017-09-15</a>

	</div>
	<div>
	<div class="number-l">76</div>
	<p>< 1% match (Internet from 14-Mar-2022)</p>

	<a style="color:#63009c" href="https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/21697/Gomez_LuisA_MSc.pdf?isAllowed=y&sequence=1">https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/21697/Gomez_LuisA_MSc.pdf?isAllowed=y&sequence=1</a>

	</div>
	<div>
	<div class="number-l">77</div>
	<p>< 1% match (Internet from 18-Feb-2022)</p>

	<a style="color:#A85503" href="https://deepai.org/publication/multilevel-delayed-acceptance-mcmc">https://deepai.org/publication/multilevel-delayed-acceptance-mcmc</a>

	</div>
	<div>
	<div class="number-l">78</div>
	<p>< 1% match (Internet from 20-Nov-2021)</p>

	<a style="color:#cc0066" href="https://deepai.org/publication/variational-rejection-sampling">https://deepai.org/publication/variational-rejection-sampling</a>

	</div>
	<div>
	<div class="number-l">79</div>
	<p>< 1% match (Internet from 30-Oct-2020)</p>

	<a style="color:#21785B" href="http://proxy.osapublishing.org/osac/fulltext.cfm?id=427725&uri=osac-3-3-401">http://proxy.osapublishing.org/osac/fulltext.cfm?id=427725&uri=osac-3-3-401</a>

	</div>
	<div>
	<div class="number-l">80</div>
	<p>< 1% match (Internet from 04-Jan-2022)</p>

	<a style="color:#336699" href="https://mobt3ath.com/uplode/books/book-93010.pdf">https://mobt3ath.com/uplode/books/book-93010.pdf</a>

	</div>
	<div>
	<div class="number-l">81</div>
	<p>< 1% match (Internet from 04-Jan-2022)</p>

	<a style="color:#D10A0A" href="https://mobt3ath.com/uplode/books/book-93029.pdf">https://mobt3ath.com/uplode/books/book-93029.pdf</a>

	</div>
	<div>
	<div class="number-l">82</div>
	<p>< 1% match (Internet from 02-Feb-2021)</p>

	<a style="color:#287B28" href="http://wrap.warwick.ac.uk/147853/1/WRAP_Theses_Jewson_2019.pdf">http://wrap.warwick.ac.uk/147853/1/WRAP_Theses_Jewson_2019.pdf</a>

	</div>
	<div>
	<div class="number-l">83</div>
	<p>< 1% match (Internet from 17-Oct-2010)</p>

	<a style="color:blue" href="http://www.tinbergen.nl/~cbos/thesis/thesis_bibliography.html">http://www.tinbergen.nl/~cbos/thesis/thesis_bibliography.html</a>

	</div>
	<div>
	<div class="number-l">84</div>
	<p>< 1% match (publications)</p>

	<a style="color:brown" href="https://doi.org/10.1109/ICASSP.2018.8461532">Sotirios P. Chatzis. "Indian Buffet Process Deep Generative Models for Semi-Supervised Classification", 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018</a>

	</div>
	<div>
	<div class="number-l">85</div>
	<p>< 1% match (Internet from 24-Feb-2022)</p>

	<a style="color:#B64B01" href="https://ebin.pub/machine-learning-9811519668-9789811519666.html">https://ebin.pub/machine-learning-9811519668-9789811519666.html</a>

	</div>
	<div>
	<div class="number-l">86</div>
	<p>< 1% match (Internet from 01-Nov-2021)</p>

	<a style="color:#630000" href="https://ebin.pub/advances-in-knowledge-discovery-and-data-mining-25th-pacific-asia-conference-pakdd-2021-virtual-event-may-1114-2021-proceedings-part-i-lecture-notes-in-computer-science-12712-1st-ed-2021-3030757617-9783030757618.html">https://ebin.pub/advances-in-knowledge-discovery-and-data-mining-25th-pacific-asia-conference-pakdd-2021-virtual-event-may-1114-2021-proceedings-part-i-lecture-notes-in-computer-science-12712-1st-ed-2021-3030757617-9783030757618.html</a>

	</div>
	<div>
	<div class="number-l">87</div>
	<p>< 1% match (student papers from 26-May-2017)</p>

	<a style="color:#0270B6" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:73328973&n=2&perc=0">Submitted to University of Bristol  on 2017-05-26</a>

	</div>
	<div>
	<div class="number-l">88</div>
	<p>< 1% match (Internet from 21-Dec-2021)</p>

	<a style="color:#330099" href="https://ora.ox.ac.uk/objects/uuid:d912c4de-4b08-4729-aa19-766413735e2a/download_file?file_format=pdf&safe_filename=BrooksPaigeThesisFinal.pdf&type_of_work=Thesis">https://ora.ox.ac.uk/objects/uuid:d912c4de-4b08-4729-aa19-766413735e2a/download_file?file_format=pdf&safe_filename=BrooksPaigeThesisFinal.pdf&type_of_work=Thesis</a>

	</div>
	<div>
	<div class="number-l">89</div>
	<p>< 1% match (publications)</p>

	<a style="color:#227967" href="https://doi.org/10.1007/978-3-319-94463-0">Charu C. Aggarwal. "Neural Networks and Deep Learning", Springer Science and Business Media LLC, 2018</a>

	</div>
	<div>
	<div class="number-l">90</div>
	<p>< 1% match (Internet from 13-Sep-2014)</p>

	<a style="color:#CB0099" href="http://www.cinematography.net/C300-Frames/C-log/C-log17.tga">http://www.cinematography.net/C300-Frames/C-log/C-log17.tga</a>

	</div>
	<div>
	<div class="number-l">91</div>
	<p>< 1% match (student papers from 21-Sep-2020)</p>

	<a style="color:#006331" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:635895679&n=2&perc=0">Submitted to University College London  on 2020-09-21</a>

	</div>
	<div>
	<div class="number-l">92</div>
	<p>< 1% match (Internet from 09-Oct-2018)</p>

	<a style="color:#795AB9" href="http://malllabiisc.github.io/publications/papers/reside_emnlp18.pdf">http://malllabiisc.github.io/publications/papers/reside_emnlp18.pdf</a>

	</div>
	<div>
	<div class="number-l">93</div>
	<p>< 1% match (Internet from 19-Jun-2017)</p>

	<a style="color:#935F32" href="http://www.dtic.mil/dtic/tr/fulltext/u2/a567404.pdf">http://www.dtic.mil/dtic/tr/fulltext/u2/a567404.pdf</a>

	</div>
	<div>
	<div class="number-l">94</div>
	<p>< 1% match (Verdicchio, Mic. "Gene Regulatory Networks: Modeling, Intervention and Context", Proquest, 2014.)</p>

	<a style="color:#ce0031" href="">Verdicchio, Mic. "Gene Regulatory Networks: Modeling, Intervention and Context", Proquest, 2014.</a>

	</div>
	<div>
	<div class="number-l">95</div>
	<p>< 1% match (Internet from 16-Jan-2020)</p>

	<a style="color:#866712" href="https://dblp.uni-trier.de/pers/hd/g/Gu:Shixiang">https://dblp.uni-trier.de/pers/hd/g/Gu:Shixiang</a>

	</div>
	<div>
	<div class="number-l">96</div>
	<p>< 1% match (Internet from 03-Mar-2008)</p>

	<a style="color:#63009c" href="http://www.eecs.umich.edu/~faloul/Papers/faloul_symcon02.pdf">http://www.eecs.umich.edu/~faloul/Papers/faloul_symcon02.pdf</a>

	</div>
	<div>
	<div class="number-l">97</div>
	<p>< 1% match ()</p>

	<a style="color:#A85503" href="https://doi.org/10.7916/d8-qkrz-sv89">Bittner, Sean Robert. "Building theories of neural circuits with machine learning", 'Columbia University Libraries/Information Services', 2021</a>

	</div>
	<div>
	<div class="number-l">98</div>
	<p>< 1% match (Internet from 17-Jan-2020)</p>

	<a style="color:#cc0066" href="https://id.scribd.com/doc/313737030/The-Machine-Question">https://id.scribd.com/doc/313737030/The-Machine-Question</a>

	</div>
	<div>
	<div class="number-l">99</div>
	<p>< 1% match (Internet from 02-Sep-2021)</p>

	<a style="color:#21785B" href="https://portal.research.lu.se/ws/files/101714577/opponent_ex_Samuel.pdf">https://portal.research.lu.se/ws/files/101714577/opponent_ex_Samuel.pdf</a>

	</div>
	<div>
	<div class="number-l">100</div>
	<p>< 1% match (Internet from 24-Feb-2022)</p>

	<a style="color:#336699" href="https://s3-eu-west-1.amazonaws.com/pstorage-cmu-348901238291901/14842073/Lange_cmu_0041E_10365.pdf">https://s3-eu-west-1.amazonaws.com/pstorage-cmu-348901238291901/14842073/Lange_cmu_0041E_10365.pdf</a>

	</div>
	<div>
	<div class="number-l">101</div>
	<p>< 1% match (publications)</p>

	<a style="color:#D10A0A" href="http://linkinghub.elsevier.com/retrieve/pii/S1090513817301186">Brooke A. Scelza, Sean P. Prall. "Partner preferences in the context of concurrency: What Himba want in formal and informal partners", Evolution and Human Behavior, 2018</a>

	</div>
	<div>
	<div class="number-l">102</div>
	<p>< 1% match (Cheng, Pengyu. "Improving Natural Language Understanding via Contrastive Learning Methods", Duke University, 2021)</p>

	<a style="color:#287B28" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28322250">Cheng, Pengyu. "Improving Natural Language Understanding via Contrastive Learning Methods", Duke University, 2021</a>

	</div>
	<div>
	<div class="number-l">103</div>
	<p>< 1% match (student papers from 26-Mar-2015)</p>

	<a style="color:blue" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:41388423&n=2&perc=0">Submitted to University of Durham  on 2015-03-26</a>

	</div>
	<div>
	<div class="number-l">104</div>
	<p>< 1% match (publications)</p>

	<a style="color:brown" href="https://doi.org/10.1088/1361-6560/ac36a2">Zabir Al Nazi, Fazla Rabbi Mashrur, Md Amirul Islam, Shumit Saha. "Fibro-CoSANet: pulmonary fibrosis prognosis prediction using a convolutional self attention network", Physics in Medicine & Biology, 2021</a>

	</div>
	<div>
	<div class="number-l">105</div>
	<p>< 1% match (Internet from 15-Feb-2022)</p>

	<a style="color:#B64B01" href="https://pdffox.com/automatic-variational-inference-in-stan-pdf-free.html">https://pdffox.com/automatic-variational-inference-in-stan-pdf-free.html</a>

	</div>
	<div>
	<div class="number-l">106</div>
	<p>< 1% match (Khodayi-mehr, Reza. "Model-Based Learning and Control of Advection-Diffusion Transport Using Mobile Robots.", Duke University, 2019)</p>

	<a style="color:#630000" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:13806890">Khodayi-mehr, Reza. "Model-Based Learning and Control of Advection-Diffusion Transport Using Mobile Robots.", Duke University, 2019</a>

	</div>
	<div>
	<div class="number-l">107</div>
	<p>< 1% match (publications)</p>

	<a style="color:#0270B6" href="https://doi.org/10.1109/MFI52462.2021.9591184">Ola Ronning, Christophe Ley, Kanti V. Mardia, Thomas Hamelryck. "Time-efficient Bayesian Inference for a (Skewed) Von Mises Distribution on the Torus in a Deep Probabilistic Programming Language", 2021 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI), 2021</a>

	</div>
	<div>
	<div class="number-l">108</div>
	<p>< 1% match (student papers from 14-Sep-2021)</p>

	<a style="color:#330099" href="/paperInfo.asp?r=47.571057331588&svr=54&lang=en_us&oid=oid:2:671190883&n=2&perc=0">Submitted to The University of Manchester on 2021-09-14</a>

	</div>
	<div>
	<div class="number-l">109</div>
	<p>< 1% match (Internet from 09-Jul-2003)</p>

	<a style="color:#227967" href="http://csl.cornell.edu/courses/ee572/handouts/pa3.pdf">http://csl.cornell.edu/courses/ee572/handouts/pa3.pdf</a>

	</div>
	<div>
	<div class="number-l">110</div>
	<p>< 1% match (Internet from 14-Jul-2021)</p>

	<a style="color:#CB0099" href="https://d-nb.info/1235139425/34">https://d-nb.info/1235139425/34</a>

	</div>
	<div>
	<div class="number-l">111</div>
	<p>< 1% match (Internet from 04-Apr-2021)</p>

	<a style="color:#006331" href="http://digilib2.unisayogya.ac.id/xmlui/bitstream/handle/123456789/2601/109%20forsyth2018.pdf?isAllowed=y&sequence=1">http://digilib2.unisayogya.ac.id/xmlui/bitstream/handle/123456789/2601/109%20forsyth2018.pdf?isAllowed=y&sequence=1</a>

	</div>
	<div>
	<div class="number-l">112</div>
	<p>< 1% match (Internet from 08-Jul-2019)</p>

	<a style="color:#795AB9" href="http://drops.dagstuhl.de/opus/volltexte/2019/10773/pdf/lipics-vol131-fscd2019-complete.pdf">http://drops.dagstuhl.de/opus/volltexte/2019/10773/pdf/lipics-vol131-fscd2019-complete.pdf</a>

	</div>
	<div>
	<div class="number-l">113</div>
	<p>< 1% match (Internet from 09-Feb-2021)</p>

	<a style="color:#935F32" href="https://epdf.pub/mining-text-datac1b34ef0e78cbf121ce72b45a27a71a064148.html">https://epdf.pub/mining-text-datac1b34ef0e78cbf121ce72b45a27a71a064148.html</a>

	</div>
	<div>
	<div class="number-l">114</div>
	<p>< 1% match (Internet from 21-May-2019)</p>

	<a style="color:#ce0031" href="https://epdf.tips/advanced-statistical-mechanics.html">https://epdf.tips/advanced-statistical-mechanics.html</a>

	</div>
	<div>
	<div class="number-l">115</div>
	<p>< 1% match (Internet from 20-Dec-2019)</p>

	<a style="color:#866712" href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0685.PDF">https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0685.PDF</a>

	</div>
	<div>
	<div class="number-l">116</div>
	<p>< 1% match (Guha, Aritra. "Inference and Interpretability in Latent Variable Modeling", University of Michigan, 2021)</p>

	<a style="color:#63009c" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28240136">Guha, Aritra. "Inference and Interpretability in Latent Variable Modeling", University of Michigan, 2021</a>

	</div>
	<div>
	<div class="number-l">117</div>
	<p>< 1% match (publications)</p>

	<a style="color:#A85503" href="https://doi.org/10.1016/j.physd.2006.08.023">Ihler, A.T.. "Graphical models for statistical inference and data assimilation", Physica D: Nonlinear Phenomena, 200706</a>

	</div>
	<div>
	<div class="number-l">118</div>
	<p>< 1% match (publications)</p>

	<a style="color:#cc0066" href="https://doi.org/10.1007/978-3-030-80421-3_10">Jialin Yu, Laila Alrajhi, Anoushka Harit, Zhongtian Sun, Alexandra I. Cristea, Lei Shi. "Chapter 10 Exploring Bayesian Deep Learning for Urgent Instructor Intervention Need in MOOC Forums", Springer Science and Business Media LLC, 2021</a>

	</div>
	<div>
	<div class="number-l">119</div>
	<p>< 1% match (Wang, Kuangyu. "Statistical Inference via Structurally and Functionally Informed Models of Protein Evolution.", Proquest, 2015.)</p>

	<a style="color:#21785B" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:3690388">Wang, Kuangyu. "Statistical Inference via Structurally and Functionally Informed Models of Protein Evolution.", Proquest, 2015.</a>

	</div>
	<div>
	<div class="number-l">120</div>
	<p>< 1% match (Internet from 09-Apr-2016)</p>

	<a style="color:#336699" href="http://aaai.org/ocs/index.php/FSS/FSS13/paper/download/7619/7563">http://aaai.org/ocs/index.php/FSS/FSS13/paper/download/7619/7563</a>

	</div>
	<div>
	<div class="number-l">121</div>
	<p>< 1% match (Internet from 05-Sep-2021)</p>

	<a style="color:#D10A0A" href="https://babel.hathitrust.org/cgi/pt?id=hvd.32044094007911">https://babel.hathitrust.org/cgi/pt?id=hvd.32044094007911</a>

	</div>
	<div>
	<div class="number-l">122</div>
	<p>< 1% match (Internet from 30-Nov-2017)</p>

	<a style="color:#287B28" href="http://scholarbank.nus.edu.sg/bitstream/10635/37889/1/MiaoWM.pdf">http://scholarbank.nus.edu.sg/bitstream/10635/37889/1/MiaoWM.pdf</a>

	</div>
	<div>
	<div class="number-l">123</div>
	<p>< 1% match (Internet from 18-Nov-2020)</p>

	<a style="color:blue" href="https://www.paperdigest.org/2020/02/aaai-2020-highlights/">https://www.paperdigest.org/2020/02/aaai-2020-highlights/</a>

	</div>
	<div>
	<div class="number-l">124</div>
	<p>< 1% match (Internet from 24-Dec-2021)</p>

	<a style="color:brown" href="https://www.science.gov/topicpages/l/loc+american+memory">https://www.science.gov/topicpages/l/loc+american+memory</a>

	</div>
	<div>
	<div class="number-l">125</div>
	<p>< 1% match (Internet from 21-Sep-2021)</p>

	<a style="color:#B64B01" href="http://www.stat.columbia.edu/%7Egelman/research/published/advi_nips2015.pdf">http://www.stat.columbia.edu/%7Egelman/research/published/advi_nips2015.pdf</a>

	</div>
	<div>
	<div class="number-l">126</div>
	<p>< 1% match (publications)</p>

	<a style="color:#630000" href="https://doi.org/10.1007/978-3-030-75768-7">"Advances in Knowledge Discovery and Data Mining", Springer Science and Business Media LLC, 2021</a>

	</div>
	<div>
	<div class="number-l">127</div>
	<p>< 1% match (Campos Manzo, Luis Fernando. "Fortunes and Misadventures with Parametric Models: They Can Be Confounding, Burdensome and Unstable, Yet Insightful, Powerful and Flexible.", Harvard University, 2020)</p>

	<a style="color:#0270B6" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28235437">Campos Manzo, Luis Fernando. "Fortunes and Misadventures with Parametric Models: They Can Be Confounding, Burdensome and Unstable, Yet Insightful, Powerful and Flexible.", Harvard University, 2020</a>

	</div>
	<div>
	<div class="number-l">128</div>
	<p>< 1% match (publications)</p>

	<a style="color:#330099" href="https://doi.org/10.1101/702944">Mathieu Fourment, Aaron E. Darling. "Evaluating probabilistic programming and fast variational Bayesian inference in phylogenetics", Cold Spring Harbor Laboratory, 2019</a>

	</div>
	<div>
	<div class="number-l">129</div>
	<p>< 1% match (publications)</p>

	<a style="color:#227967" href="https://doi.org/10.1007/978-1-4842-2872-2">Matt Wiley, Joshua F. Wiley. "Advanced R Statistical Programming and Data Models", Springer Science and Business Media LLC, 2019</a>

	</div>
	<div>
	<div class="number-l">130</div>
	<p>< 1% match (McAlister, Kevin A.. "Essays on Latent Variable Models and Roll Call Scaling", University of Michigan, 2021)</p>

	<a style="color:#CB0099" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28240195">McAlister, Kevin A.. "Essays on Latent Variable Models and Roll Call Scaling", University of Michigan, 2021</a>

	</div>
	<div>
	<div class="number-l">131</div>
	<p>< 1% match (publications)</p>

	<a style="color:#006331" href="https://doi.org/10.1109/ICASSP.2019.8683633">Shang-Yu Su, Shan-Wei Lin, Yun-Nung Chen. "Compound Variational Auto-encoder", ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019</a>

	</div>
	<div>
	<div class="number-l">132</div>
	<p>< 1% match (Wu, Ga. "One-Class Collaborative Filtering with Latent Embeddings: Improvements and Interactive Extensions", University of Toronto (Canada), 2020)</p>

	<a style="color:#795AB9" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:27961165">Wu, Ga. "One-Class Collaborative Filtering with Latent Embeddings: Improvements and Interactive Extensions", University of Toronto (Canada), 2020</a>

	</div>
	<div>
	<div class="number-l">133</div>
	<p>< 1% match (publications)</p>

	<a style="color:#935F32" href="https://doi.org/10.1029/2019JB018589">Xin Zhang, Andrew Curtis. "Seismic Tomography Using Variational Inference Methods", Journal of Geophysical Research: Solid Earth, 2020</a>

	</div>
	<div>
	<div class="number-l">134</div>
	<p>< 1% match (Internet from 27-Feb-2019)</p>

	<a style="color:#ce0031" href="http://bayesiandeeplearning.org/2016/papers/BDL_41.pdf">http://bayesiandeeplearning.org/2016/papers/BDL_41.pdf</a>

	</div>
	<div>
	<div class="number-l">135</div>
	<p>< 1% match (Internet from 13-Dec-2021)</p>

	<a style="color:#866712" href="http://nozdr.ru/data/media/biblio/kolxoz/Cs/CsLn/Probabilistic%20Inductive%20Logic%20Programming%20-%20Theory%20and%20Applications%28LNCS4911,%20Springer,%202008%29%28ISBN%209783540786511%29%28347s%29.pdf">http://nozdr.ru/data/media/biblio/kolxoz/Cs/CsLn/Probabilistic%20Inductive%20Logic%20Programming%20-%20Theory%20and%20Applications%28LNCS4911,%20Springer,%202008%29%28ISBN%209783540786511%29%28347s%29.pdf</a>

	</div>
	<div>
	<div class="number-l">136</div>
	<p>< 1% match (Internet from 03-Apr-2021)</p>

	<a style="color:#63009c" href="http://reports-archive.adm.cs.cmu.edu/anon/anon/home/ftp/home/ftp/ml2019/CMU-ML-19-113.pdf">http://reports-archive.adm.cs.cmu.edu/anon/anon/home/ftp/home/ftp/ml2019/CMU-ML-19-113.pdf</a>

	</div>
	<div>
	<div class="number-l">137</div>
	<p>< 1% match (Internet from 11-Jul-2021)</p>

	<a style="color:#A85503" href="https://repositories.lib.utexas.edu/bitstream/handle/2152/83980/YIN-DISSERTATION-2020.pdf">https://repositories.lib.utexas.edu/bitstream/handle/2152/83980/YIN-DISSERTATION-2020.pdf</a>

	</div>
	<div>
	<div class="number-l">138</div>
	<p>< 1% match (Internet from 13-Jul-2019)</p>

	<a style="color:#cc0066" href="https://westminsterresearch.westminster.ac.uk/download/fe16e9043d15d2f9e0c3434f9667c4b1e0074eae50656d4f5e84b06cec23ae5d/41274709/Mesgarpour_Mohsen_thesis.pdf">https://westminsterresearch.westminster.ac.uk/download/fe16e9043d15d2f9e0c3434f9667c4b1e0074eae50656d4f5e84b06cec23ae5d/41274709/Mesgarpour_Mohsen_thesis.pdf</a>

	</div>
	<div>
	<div class="number-l">139</div>
	<p>< 1% match (Internet from 11-Nov-2020)</p>

	<a style="color:#21785B" href="https://www.ig.com/nl/sitemap-ig">https://www.ig.com/nl/sitemap-ig</a>

	</div>
	<div>
	<div class="number-l">140</div>
	<p>< 1% match (Internet from 17-Aug-2019)</p>

	<a style="color:#336699" href="http://www.mtome.com/Publications/JMLR/jmlr-vol13-partC.pdf">http://www.mtome.com/Publications/JMLR/jmlr-vol13-partC.pdf</a>

	</div>
	<div>
	<div class="number-l">141</div>
	<p>< 1% match (publications)</p>

	<a style="color:#D10A0A" href="https://doi.org/10.1007/978-3-030-13469-3">"Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications", Springer Science and Business Media LLC, 2019</a>

	</div>
	<div>
	<div class="number-l">142</div>
	<p>< 1% match (Huang, Mi. "Developing Probabilistic Graphical Models for Identifying Text Patterns and Semantics", Proquest, 2014.)</p>

	<a style="color:#287B28" href="">Huang, Mi. "Developing Probabilistic Graphical Models for Identifying Text Patterns and Semantics", Proquest, 2014.</a>

	</div>
	<div>
	<div class="number-l">143</div>
	<p>< 1% match (publications)</p>

	<a style="color:blue" href="https://doi.org/10.1145/1131313.1131317">Agostino Dovier. "Decidability results for sets with atoms", ACM Transactions on Computational Logic, 4/1/2006</a>

	</div>
	<div>
	<div class="number-l">144</div>
	<p>< 1% match (publications)</p>

	<a style="color:brown" href="https://doi.org/10.1109/ICHIS.2005.22">F.J. Von Zuben. "An Immune-Inspired Approach to Bayesian Networks", Fifth International Conference on Hybrid Intelligent Systems (HIS 05), 2005</a>

	</div>
	<div>
	<div class="number-l">145</div>
	<p>< 1% match (Han, Tian. "Unsupervised Learning and Understanding of Deep Generative Models.", University of California, Los Angeles, 2019)</p>

	<a style="color:#B64B01" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:13811689">Han, Tian. "Unsupervised Learning and Understanding of Deep Generative Models.", University of California, Los Angeles, 2019</a>

	</div>
	<div id="last">
	<div class="number-l">146</div>
	<p>< 1% match (Mukherjee, Sudipto. "Unsupervised Learning: Model-Guided and Model-Agnostic Approaches.", University of Washington, 2020)</p>

	<a style="color:#630000" href="http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:28087403">Mukherjee, Sudipto. "Unsupervised Learning: Model-Guided and Model-Agnostic Approaches.", University of Washington, 2020</a>

	</div>

</div>



<div class="divider">paper text:</div>
<div id="body">
Improved Autoguides for Probabilistic Programs Jiaqing Xie E UNI VERS I H T T Y O F H E R G D INB U 4th Year Project Report Electronics <a href="javascript:openDSC(666085429, 37, '82');" onmouseover="doRollover(58);" onmouseout="undoRollover(58);" id="82" name="58" style="color:#cc0066" class="#cc0066"><span class="b-ref">58</span>and Computer Science<span> School </span>of<span> Informatics </span>University of</a> Edinburgh 2022 Abstract Variational inference (VI) can usually be used to simulate a complex posterior distribu- tion. Using automatic differentiation in VI facilitates inference as optimization since it does not require specifying an importance distribution, which is implemented in Pyro as autoguides. Pyro’s two simplest autoguides are based on the full-rank and mean-field assumptions. However, the mean-field assumption does not account for dependent variables while full-rank assumptions lack the enrichness choices of covariance matri- ces, which may compromise inference performance. In this project, we developed six different covariance matrices based autoguides. We proposed another two autoguides based on the inverse model dependencies to guide the poesterior more accurately. We have evaluated our new autoguides on different datasets, the degree of improvement when using new autoguides, and the relevant scenarios for the autoguides. In gen- eral, the autoguide based on a covariance matrix is appropriate for low dimensional tasks, whereas the autoguide based on an inversed dependency model is appropriate for high dimensional tasks with enriched dependency structures. It is important to note that autoguides are not suitable for many deep generative models such as variational encoders. i Research Ethics Approval This project was planned in accordance with the Informatics Research Ethics policy. It did not involve any aspects that required approval from the Informatics Research Ethics committee. <a href="javascript:openDSC(11855509, 2, '54');" onmouseover="doRollover(42);" onmouseout="undoRollover(42);" id="54" name="42" style="color:#287B28" class="#287B28"><span class="b-ref">42</span>Declaration I declare that this thesis was composed by myself, that the work contained herein is my own except where explicitly stated otherwise in the text, and that this work has not been submitted for any other degree or professional qualification except as specified<span>. (Jiaqing </span>Xie</a>) ii Acknowledgements It has been a real challenge to do this project. When I worked on this project, I often did not make progress, and it was very difficult to realize the code. Because of insufficient coding, mathematical, and logic knowledge, I sometimes felt pressure and failed to reproduce some algorithms and source code myself. I nearly collapsed and fell into depression for two months. Now that I have followed people’s advice, I feel much better and would like to thank them all individually here. <a href="javascript:openDSC(3806177778, 3722, '171');" onmouseover="doRollover(138);" onmouseout="undoRollover(138);" id="171" name="138" style="color:#cc0066" class="#cc0066"><span class="b-ref">138</span>I am<span> very </span>grateful to my supervisor Prof<span>. Siddharth Narayanaswamy, </span>and</a> my second marker Prof. Mary Cryan, for helping me achieve small goals instead of being unable to accomplish anything. In the end, there are some significant improvements based on their careful advice, although the results are not as good as expected. Thanks to Dr. Eli Bingham, the developer and leader of Pyro, for helping me solve a lot of conceptual problems. He also explained some of his ideas as I worked on Pyro. He played an extremely crucial role in assisting me understand Pyro’s entire framework. My thanks also extend to Dr. Tuan Anh Le for helping me understand the paper. I had a lot of misguided ideas about the inference compilation part of the paper. Additionally, <a href="javascript:openDSC(741217477, 917, '135');" onmouseover="doRollover(102);" onmouseout="undoRollover(102);" id="135" name="102" style="color:#287B28" class="#287B28"><span class="b-ref">102</span>I would like to express my gratitude to Dr<span>. Nicholas Polydorides, </span>who<span> taught </span>me</a> advanced algebraic techniques. As well, I’d <a href="javascript:openDSC(703945672, 917, '149');" onmouseover="doRollover(116);" onmouseout="undoRollover(116);" id="149" name="116" style="color:#63009c" class="#63009c"><span class="b-ref">116</span>like to express my gratitude to my parents<span>, Mr. Shengliang Xie </span>and</a> Mrs. Zhaodi Shan, as well as my two best friends, Jingwen Pan and Jiaqi Huang. They helped me when I nearly collapsed. Thanks to all of you, this dissertation would not have been possible without your assistance and understanding. iii <a href="javascript:openDSC(193571889, 3798, '107');" onmouseover="doRollover(76);" onmouseout="undoRollover(76);" id="107" name="76" style="color:#63009c" class="#63009c"><span class="b-ref">76</span>Table of Contents 1 Introduction 1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3<span> Main </span>contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.4<span> Report outlines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . </span>2<span> Background </span>2.1</a> What is inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2 Bayesian inference . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2.1 Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2.2 Extension on Bayes . . . . . . . . . . . . . . . . . . . . . . . 2.3 Variational inference . . . . . . . . . . . . . . . . . . . . . . . . . . 2.3.1 Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.3.2 Optimization problem . . . . . . . . . . . . . . . . . . . . . 2.3.3 Variational expectation maximization . . . . . . . . . . . . . 2.3.4 Forms of variational inference . . . . . . . . . . . . . . . . . 2.4 Probabilistic Programming . . . . . . . . . . . . . . . . . . . . . . . 2.4.1 Definition and Languages . . . . . . . . . . . . . . . . . . . 2.4.2 Main PPL: Pyro . . . . . . . . . . . . . . . . . . . . . . . . 2.5 Bayesian Networks (BN) . . . . . . . . . . . . . . . . . . . . . . . . 2.5.1 Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.5.2 Important Properties of BN . . . . . . . . . . . . . . . . . . . 2.5.3 BN with Variational Inference . . . . . . . . . . . . . . . . . 3 ADVI and potential improvements 3.1 Problem Restatement . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 ADVI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3 Learning Inverse Dependencies . . . . . . . . . . . . . . . . . . . . . 3.3.1 Observed to latent (Upstream) . . . . . . . . . . . . . . . . . 3.3.2 Latent to observed (Downstream) . . . . . . . . . . . . . . . 3.4 Covariance Matrices’ Variants . . . . . . . . . . . . . . . . . . . . . 3.4.1 PolyDiagNorm . . . . . . . . . . . . . . . . . . . . . . . . . 3.4.2 SymmetricNorm . . . . . . . . . . . . . . . . . . . . . . . . 3.4.3 LowRankNorm . . . . . . . . . . . . . . . . . . . . . . . . . 3.4.4 BlockDiagNorm . . . . . . . . . . . . . . . . . . . . . . . . 1 1 1 2 2 3 3 4 4 5 6 6 7 8 8 10 10 10 11 11 12 13 14 14 15 18 19 20 22 22 23 23 24 iv 3.4.5 ToeplitzNorm . . . . . . . . . . . . . . . . . . . . . . . . . . 3.4.6 CirculantNorm . . . . . . . . . . . . . . . . . . . . . . . . . 3.5 Inference Compilation . . . . . . . . . . . . . . . . . . . . . . . . . 3.5.1 Difference from Variational Inference . . . . . . . . . . . . . 3.5.2 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Evaluation 4.1 Environment settings . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Datasets and tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2.1 GMM data . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2.2 National Income Dataset . . . . . . . . . . . . . . . . . . . . 4.2.3 MNIST . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2.4 OSIC Pulmonary Fibrosis . . . . . . . . . . . . . . . . . . . 4.2.5 Daily S&amp;P 500 dataset . . . . . . . . . . . . . . . . . . . . . 4.2.6 SARS-COV-2 . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Tested autoguides . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.4 Aims of experiments (tasks) . . . . . . . . . . . . . . . . . . . . . . 4.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Discussions and Conclusions 5.1 Results overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2 Discussions and future works . . . . . . . . . . . . . . . . . . . . . . 5.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Bibliography A Others A.1 Code implementations . . . . . . . . . . . . . . . . . . . . . . . . . 24 25 25 26 26 28 28 28 28 29 29 29 29 30 30 30 31 39 39 39 40 41 46 46 v Chapter 1 Introduction 1.1 Motivation Analyzing latent variables or distribution parameters from observed data is the central question of inference. The problem is also referred to as posterior estimation. Studies have been conducted on solving the inference problems either using sampling methods [10, 58, 59], or variational inference [24, 29, 31, 53, 57, 71]. The majority of variational inferences make use of mean-field or full-rank assumptions [4]. According to the mean-field assumption, latent variables are independent of each other, while the full- rank assumption extends this by using Cholesky factorization [19] and extending the covariance matrix to be unconstrained by positive definite requirements. Both of these methods have been implemented in Pyro, a mainstream programming language, as a form of autoguide. Essentially, they use the automated differentiation during variational inference (ADVI) method [33]. When autoguides are used, each model’s original parameters are transformed into a Gaussian latent space. The two previous autoguides have some drawbacks. Taking the mean-field approach might lead to a loss of latent variable dependencies. Assuming the full-rank situation, we will always have to perform Cholesky factorization with inserting it into the parameter scale tril of the Gaussian distribution. It removes the positive definite requirement, but neglects the importance of different kinds of special covariance matrices. Therefore, we aim at extending the covariance matrix group of autoguides as well as getting the inverse dependency by either using faithful inversion [69] or stochastic inverse [24] of the model dependencies to create new autoguides. Though AutoStructured is implemented, the node order is given in an unconvincing reversed order that might lose dependency information at higher dimensions. In order to construct a convincing dependency-based guide, there is a need to present it in a more structured manner. 1.2 Objectives This project is primarily intended to build new autoguides and perform inference tests on different datasets and models. The objectives of this project are, 1 Chapter 1. Introduction • To design autoguides using various covariance matrices • To design autoguides using inverse dependency models • To test those new autoguides on different datasets, observe the loss, and report the latent variable patterns in several models and datasets • To generalize the autoguides’ usage range by comparing them to other baseline autoguides or just simple guides. 1.3 Main contributions Contributions to this project are as follows: • I contributed eight new autoguides, including six based on covariance matrices, and two others based on different inverse dependency models, including topo- logical ordering of the graph and minimum distance ordering given the observed node. • I compared the performance of different autoguides on different datasets, and combined them with images to explain why some parameters did not fit, the limi- tations of generating new data using posterior probabilities, and some potential tradeoffs. • I reviewed a lot of literature on variational inference as well as advanced algebra books, with a more thorough and detailed description of the background and method part, finally translating the theory to code. 1.4 Report outlines The following is the order in which I organize this dissertation: • Chapter 1 outlines project’s goals, main objectives, and main personal contribu- tions to the project. • Chapter 2 introduces the fundamentals of the project, including Bayesian infer- ence, variational inference, probabilistic programming, and Bayesian networks. • Chapter 3 describes the sources of autoguide, as well as improvements based on inversed model dependencies, covariance matrices, and RNN autoguide. • Chapter 4 describes how some of our improved methods developed in chapter 3 are applied to the datasets used of inference and how some rules and conclusions about the use of autoguides are formulated. • Chapter 5 summarizes the results of implementations, discusses the deficiencies, suggests some improvements to be made in the future work, and summarizes the whole project. Chapter 2 Background Chapter 2 has provided the basic understanding of the project’s fundamentals and we will discuss: 1) an explanation of inference problems and some real-world examples 2) what Bayesian inference is and its pros and cons 3) what methods have been used to improve Bayesian inference; 4) a guide to variational inference 5) probabilistic programming as a tool to translate theory into practice 6) the relationship between Bayesian networks and inference 7) Bayesian network representation with probability distributions. 2.1 What is inference Understanding what a hypothesis is is the first step to understanding inference. We are affected by the weather conditions on a daily basis. If nothing happens, rain is predicted to occur 50% of the time. Thus, a hypothesis can be defined mathematically as the probability that a probabilistic event occurs without given conditions. A rainy day and a non-rainy day are two distinct events, which means 50% probability individually. The probability of rain could be higher than 60% or 70%, however, if the sky is cloudy because weather conditions are given, so we will make different probability predictions based on the weather. In this case, inference can be defined mathematically as the modification of the original hypothesis probability based on the conditions (data), that is, the probability resulting from the conditions. However, conditional probabilities do not always constitute inferences. The general rule is that premises are inferred from results. Here is another classic example of inference that can help understand it, which is cancer diagnosis. The probability of cancer occurring is extremely small, with a less than 1% chance recorded. Considering this scenario, we would like to know if the chances of getting cancer, even if we test positive, are still that small. Patients that suffer from cancer are assumed to have a positive test rate of 99%, while those who are not affected have a negative test rate of 99%. Using the joint probability distribution formula, the probability of both having this disease and testing positive is 0.99%. The marginal probability calculation formula (to simplify, it will not be expanded in detail) claims a positive rate of 10.9%, so the conditional probability that patients are diagnosed as 3 positive but still suffer from the cancer is only 8.33%. It is very rare to be diagnosed with cancer by being positive. In other words, the risk of cancer itself is small, and it is also unnecessary to worry even if being tested positive. 2.2 Bayesian inference 2.2.1 Concepts As described in 2.1, both examples fall within Bayesian inference. Generally, Bayesian statistical inference problems aim to learn unobserved variables from observed variables. This includes exploring confidence intervals and estimating latent variable distributions from observed data in the field of statistics. As more evidence and information become available, the probability of a particular hypothesis can be updated continuously. Here we abstract data and hypotheses into symbolic representations and write out a general form of Bayesian inference. We posit observed data X and unobserved patterns Z . As the center of a statistical inference problem, one has to determine how to infer the underlying pattern of z ∈ Z from unlabeled x ∈ X . Bayesian inference describes such inference dependency as a posterior probability distribution. Suppose that θ is a shared parameter for sets X and Z , along with a probability function <a href="javascript:openDSC(637507219, 917, '178');" onmouseover="doRollover(145);" onmouseout="undoRollover(145);" id="178" name="145" style="color:#B64B01" class="#B64B01"><span class="b-ref">145</span>p(Z |X ; θ<span>) that maps </span>the<span> variable </span>x</a> from original parameter space to latent (variable) space. The classic Bayes’ theorem describes an inference problem as follows: <a href="javascript:openDSC(1804901830, 1, '42');" onmouseover="doRollover(36);" onmouseout="undoRollover(36);" id="42" name="36" style="color:#63009c" class="#63009c"><span class="b-ref">36</span>p(Z |X ; θ) = p(X |Z ; θ) p(Z ; θ) p(X ; θ) (2.1</a>) Our hypotheses in 2.1 p(Z;θ) are referred to <a href="javascript:openDSC(135745519, 3793, '67');" onmouseover="doRollover(49);" onmouseout="undoRollover(49);" id="67" name="49" style="color:#227967" class="#227967"><span class="b-ref">49</span>as a<span> prior </span>probability distribution<span>, whereas </span>p(X<span>|Z;θ) </span>is</a> our conditional probability distribution. There is prior knowledge of domain experts to estimate <a href="javascript:openDSC(872254273, 3791, '26');" onmouseover="doRollover(24);" onmouseout="undoRollover(24);" id="26" name="24" style="color:brown" class="brown"><span class="b-ref">24</span>p(Z;θ<span>) and </span>p(X;Z,θ). The</a> decision on these two models is therefore subjective. Models may vary from scenario to scenario, but they are already known before any inference is made. We can present this marginal probability p(X;θ) in <a href="javascript:openDSC(737654154, 917, '62');" onmouseover="doRollover(47);" onmouseout="undoRollover(47);" id="62" name="47" style="color:#0270B6" class="#0270B6"><span class="b-ref">47</span>an integral<span> form </span>if z is continuous</a> in space <a href="javascript:openDSC(1509178098, 3796, '132');" onmouseover="doRollover(99);" onmouseout="undoRollover(99);" id="132" name="99" style="color:#21785B" class="#21785B"><span class="b-ref">99</span>Z: p(X ; θ) = p(X |z<span> ∈ Z ; </span>θ) p(z<span> ∈ Z ; </span>θ<span>)d </span>z</a> ∫ z (2.2) Bayesian inference has the following advantages: • Using the posterior as a prior for new parameter updates, only a few new observa- tions are required. • It is the foundation for all inference methods. • Different prior inference designs can get the same likelihood function, where it can be interpreted easily. But it also has some obvious shortcomings: • Prior can’t be generalized and must be designed in independent cases. • Posterior is heavily dependent on prior design. • Calculating such integral (equation 2.2) is intractable in high-dimensional vector spaces for Z and sometimes we can’t achieve an analytical solution. Even if we can calculate it, it has a high computation cost. 2.2.2 Extension on Bayes The integration problem in equation 2.<a href="javascript:openDSC(641523914, 917, '139');" onmouseover="doRollover(106);" onmouseout="undoRollover(106);" id="139" name="106" style="color:#630000" class="#630000"><span class="b-ref">106</span>2 can be<span> approached </span>in<span> two </span>ways. The<span> first </span>approach is to use</a> sampling simulations. We discuss sampling in this section and a variational approach to approximating the posterior distribution in 2.3. Stochastic simu- lation poses the problem of generating samples <a href="javascript:openDSC(570104602, 37, '87');" onmouseover="doRollover(60);" onmouseout="undoRollover(60);" id="87" name="60" style="color:#336699" class="#336699"><span class="b-ref">60</span>for a probability distribution p(x<span>). The generation </span>of</a> samples may be difficult when p(x) has a complex distribution or when p(x) is a high-dimensional distribution, it is required to use more complex random sim- ulation methods. Three different methods for sampling have been discussed: (MCMC) sampling, MH sampling, and Gibbs sampling. Despite the fact that algorithms and concepts of sampling are not the primary focus of the project, I will explain them here for completeness’ sake. MCMC sampling [58] Two of the concepts introduced by MCMC sampling are Monte Carlo simulations and Markov Chain models. According to certain probabilistic rules, a Markov chain experiences state transitions. One of the most important properties is that the probability of state transition is determined solely by the previous state. According to the convergence theorem, the probability distribution of a <a href="javascript:openDSC(3950707212, 3796, '37');" onmouseover="doRollover(32);" onmouseout="undoRollover(32);" id="37" name="32" style="color:#795AB9" class="#795AB9"><span class="b-ref">32</span>Markov Chain will converge<span> itself </span>to a stationary distribution</a>. Based on the assumption that after n steps of convergence, the transition sequences after n steps will all be samples of a stationary distribution. When n reaches an infinite value, it will no longer be related to nodes or time. To satisfy the above detailed stationarity conditions, we need to construct the following transition matrix P that <a href="javascript:openDSC(823277374, 3796, '97');" onmouseover="doRollover(67);" onmouseout="undoRollover(67);" id="97" name="67" style="color:#0270B6" class="#0270B6"><span class="b-ref">67</span>it satisfies: π(i)P(i, j) = π( j<span>)P( </span>j, i</a>) (2.<a href="javascript:openDSC(51558525, 917, '152');" onmouseover="doRollover(119);" onmouseout="undoRollover(119);" id="152" name="119" style="color:#21785B" class="#21785B"><span class="b-ref">119</span>3) where π(i) is the stationary<span> distribution </span>of<span> P(</span>i</a>, j). For the above formula to hold generally, an extra α(i, j) is introduced, which is also referred to as an acceptance rate since the equation 2.3 does not always hold: <a href="javascript:openDSC(635895679, 2, '124');" onmouseover="doRollover(91);" onmouseout="undoRollover(91);" id="124" name="91" style="color:#006331" class="#006331"><span class="b-ref">91</span>π(i<span>) P(</span>i, j)α(i, j) = π( j<span>) P( </span>j, i)α( j, i</a>) (<a href="javascript:openDSC(634337439, 37, '174');" onmouseover="doRollover(141);" onmouseout="undoRollover(141);" id="174" name="141" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">141</span>2.4<span>) new </span>P’(i,j<span>) new P’(</span>j,i</a>) Using the sample xt, we coul︸d sam︷︷ple a︸x∗ from ︸the or︷i︷ginal︸transition matrix at time t. The acceptance rate would then be α(xt, x∗). The uniform distribution U ∼ (0,1) is supposed and a random value u is sampled from this distribution. The transition from xt to x∗ will be accepted if this value is less than acceptance rate. Otherwise, at time t-1, it will still have the same sample. The integral can then be transformed into a summation over a series of finite samples sampled from stationary distributions. MH sampling [59] Likewise, MH sampling is <a href="javascript:openDSC(303036208, 3788, '53');" onmouseover="doRollover(41);" onmouseout="undoRollover(41);" id="53" name="41" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">41</span>based on the state<span> transition </span>of the Markov chain</a>, but Metropolis [59] designed a new sampling method to optimize MCMC sampling. The acceptance rate α(i, j) may be too low, resulting in low sampling efficiency. In other words, sampling once is likely to reject a state transition, which may not lead to convergence. Hence, we adjust the acceptance rate as follows: α(xt , x∗) = min{ <a href="javascript:openDSC(823277374, 3796, '98');" onmouseover="doRollover(67);" onmouseout="undoRollover(67);" id="98" name="67" style="color:#0270B6" class="#0270B6"><span class="b-ref">67</span>π(i)P(i, j<span>) , 1} </span>π( j)P( j, i</a>) (2.5) The advantage of this modification is that it increases the value of the acceptance rate, which in turn increases the probability of a state being transited. There are, however, two problems associated with MH sampling. In first place, calculating the acceptance rate at high dimensions is inefficient for datasets with too many features. In addition, researchers are still not satisfied with the acceptance rate. Ideally, the probability of a state transition occurring at the next moment should be 100%. Gibbs sampling [10] Gibbs sampling then solves both of these issues. For Gibbs sampling, the stationary condition is met by using point transitions. Consider a 2- dimensional dataset with variables x1 and x2. Therefore, the sampling value at time t-1 would be xt1−1 and xt2−1. To determine the new value of xt2, the sampling of xt2 can be calculated from the value of x1 at time t-1 based on its conditional probability distribution. The sampling of xt1 is based on xt2 and its conditional probability on xt2. These two values {xt1, xt2} represent new sampling values of the distribution at time t. Higher dimension situations imply the following: one point is sampled based on the sample values of all the other points at the previous moment and the other points are sampled based on the sample values of some points at this moment, or the moment according to the dependencies between the states. During the sampling process, all other points are fixed, which is similar to the coordinate gradient (axis) descent method [67]. Alternatively, this type of sampling technique can be called cyclic sampling. 2.3 Variational inference 2.3.1 Concepts In addition to sampling, variational inference (VI) is another important method to solve the Bayesian posterior integration problem [5]. To begin, we introduce the notion of conjugate distributions, where the posterior is in the same distribution group as the prior, or in other words, they exhibit the same form. This is best illustrated by a Gaussian dis- tribution. <a href="javascript:openDSC(135745519, 3793, '68');" onmouseover="doRollover(49);" onmouseout="undoRollover(49);" id="68" name="49" style="color:#227967" class="#227967"><span class="b-ref">49</span>In the case of a<span> prior </span>Gaussian<span> distribution, </span>the posterior<span> distribution must </span>also<span> be </span>Gaussian</a>. Therefore a Gaussian distribution can be constructed to approximate this posterior <a href="javascript:openDSC(135745519, 3793, '69');" onmouseover="doRollover(49);" onmouseout="undoRollover(49);" id="69" name="49" style="color:#227967" class="#227967"><span class="b-ref">49</span>Gaussian distribution<span>, which </span>is also known as the</a> Gaussian approximation. The Dirichlet <a href="javascript:openDSC(3070846419, 3797, '133');" onmouseover="doRollover(100);" onmouseout="undoRollover(100);" id="133" name="100" style="color:#336699" class="#336699"><span class="b-ref">100</span>distribution is<span> used </span>to<span> infer </span>the parameters of<span> a multinomial </span>distribution<span>, and </span>the<span> categorical </span>distribution is used to</a> infer discrete variables. VI considers how to approximate intractable distributions. The problem is generalized that given any <a href="javascript:openDSC(73328973, 2, '119');" onmouseover="doRollover(87);" onmouseout="undoRollover(87);" id="119" name="87" style="color:#0270B6" class="#0270B6"><span class="b-ref">87</span>posterior distribution p(Z|X), where Z is set of<span> the </span>latent variables and X is<span> a group </span>of</a> data, if an approximated distribution q(Z) can be found so that it is close to p(Z|X). 2.3.2 Optimization problem Variational methods are based on optimization problems and allow for approximate inference. This is an optimization problem because we must constantly approximate the true distribution with approximate distributions, and the key to optimization is to reduce the difference between distributions. It is aimed at determining an approximate <a href="javascript:openDSC(727294997, 37, '151');" onmouseover="doRollover(118);" onmouseout="undoRollover(118);" id="151" name="118" style="color:#cc0066" class="#cc0066"><span class="b-ref">118</span>posterior distribution p(Z |X ; θ<span>) with </span>q(Z ; φ</a>) ∈ Q [5] by implementing KL-divergence loss function: q(Z ; φ) = argmin (K L(<a href="javascript:openDSC(145346898, 3793, '58');" onmouseover="doRollover(45);" onmouseout="undoRollover(45);" id="58" name="45" style="color:#B64B01" class="#B64B01"><span class="b-ref">45</span>q(Z<span> ; φ)|| </span>p(Z |X<span> ; θ))) (</span>2<span>.6) </span>q(Z<span>;φ)∈</span>Q<span> , where Q </span>is</a> a space containing a set of possible approximation distributions. KL is an abbreviation for <a href="javascript:openDSC(3082338620, 3797, '117');" onmouseover="doRollover(85);" onmouseout="undoRollover(85);" id="117" name="85" style="color:#B64B01" class="#B64B01"><span class="b-ref">85</span>Kullback-Leibler divergence, also<span> referred to </span>as relative entropy<span> in </span>the<span> context of </span>information</a> systems, and is often used to describe the difference between two distributions. We can measure the difference between approximated probability <a href="javascript:openDSC(145346898, 3793, '59');" onmouseover="doRollover(45);" onmouseout="undoRollover(45);" id="59" name="45" style="color:#B64B01" class="#B64B01"><span class="b-ref">45</span>distribution q(Z<span>;φ) </span>and<span> real probability </span>distribution p(Z|X;θ</a>) in terms of an integral form [5] where we assume that the parameter φ is the parameter to Z merely: K L(<a href="javascript:openDSC(1804901830, 1, '43');" onmouseover="doRollover(36);" onmouseout="undoRollover(36);" id="43" name="36" style="color:#63009c" class="#63009c"><span class="b-ref">36</span>q(Z ; φ)|| p(Z |X ; θ<span>)) = q(</span>Z ; φ<span>)l og </span>p(Z |X ; θ<span>) ∫ z </span>q(Z ; φ</a>) dz (2.7) Optimally, <a href="javascript:openDSC(872254273, 3791, '27');" onmouseover="doRollover(24);" onmouseout="undoRollover(24);" id="27" name="24" style="color:brown" class="brown"><span class="b-ref">24</span>q(Z<span> ; φ) = </span>p(Z |X ; θ<span>), where the value </span>of KL-divergence</a> becomes zero under this circumstance since the log term will become zero. But actually KL-divergence will never reach zero and will also experience diverging during optimization step, The value of KL(·) is always larger than zero which can be proved by Jensen’s Inequality theorem [5]. We can rewrite the equation 2.6 in the form of <a href="javascript:openDSC(834534588, 3793, '130');" onmouseover="doRollover(97);" onmouseout="undoRollover(97);" id="130" name="97" style="color:#A85503" class="#A85503"><span class="b-ref">97</span>evidence lower bound (ELBO<span>) [5]: </span>K L(q<span>(Z ; φ)|| </span>p(Z |X ; θ)) = −E</a> LBO(X ; θ; φ) + l og( p(X ; θ)) (2.8) A couple of reasons have led to the emergence of ELBO. The first reason is due to the <a href="javascript:openDSC(2753172227, 3796, '109');" onmouseover="doRollover(78);" onmouseout="undoRollover(78);" id="109" name="78" style="color:#cc0066" class="#cc0066"><span class="b-ref">78</span>fact that the<span> calculation </span>of KL divergence<span> still includes </span>the<span> calculation </span>of the</a> posterior distribution, making the calculation difficult. It is found that using ELBO, only the approximate distribution and the previously known joint probability distribution in the calculation formula make it easier to deal with the approximate distribution, such as differential or integral of variables. Additionally, the distributed maximum likelihood estimation (MLE) and KL loss do not seem to be linked directly, whereas, the ELBO is related with MLE. The ELBO represents the upper limit of the joint probability distribution (according to Jensen’s inequality) and our optimization process maintains the ELBO close to this upper limit. In other words, KL loss is usually calculated by subtracting these two indicators, which means that KL loss cannot be calculated directly. Minimization of KL-divergence in equation 2.7 is equivalent to the maximization of ELBO since calculating p(X;θ) is independent of q(Z;φ) as mentioned. Current methods are solving how to optimize ELBO. <a href="javascript:openDSC(2337155389, 3797, '16');" onmouseover="doRollover(14);" onmouseout="undoRollover(14);" id="16" name="14" style="color:#ce0031" class="#ce0031"><span class="b-ref">14</span>ELBO can also be<span> rewritten </span>as<span>: E LBO(x; </span>θ, φ) = Eq(Z</a> ;φ) l og q(Z ; φ) <a href="javascript:openDSC(737654154, 917, '63');" onmouseover="doRollover(47);" onmouseout="undoRollover(47);" id="63" name="47" style="color:#0270B6" class="#0270B6"><span class="b-ref">47</span>p(X , Z ; θ<span>) (2.9) = </span>Eq(Z ;φ<span>) l og( </span>p(X |Z ; θ<span>)) − K L(</span>q(Z ; φ)|| p<span>(Z |</span>X ; θ</a>)) (2.10) The equation is easier to understand now since the first term can be regarded as a likelihood function after reconstructing the original space from the latent space. The equation functions as a loss function during actual training in some models such as variational auto-encoders [29], and graph variational auto-encoders [31]. In part 2.3.4, various variational inference methods are illustrated. 2.3.3 Variational expectation maximization Maximum likelihood solutions can be found using an expectation maximization al- gorithm for probabilistic models with latent variables. The general EM algorithm can be brought into VI to demonstrate the relationship between ELBO and maximum likelihood. It can also demonstrate how to find the best variational distribution q and optimal distribution parameters. A typical EM procedure <a href="javascript:openDSC(3743810516, 3722, '145');" onmouseover="doRollover(112);" onmouseout="undoRollover(112);" id="145" name="112" style="color:#795AB9" class="#795AB9"><span class="b-ref">112</span>consists of two steps<span>, in which </span>the first step is to<span> keep </span>the</a> parameters fixed. ELBO maximizes the log likelihood of the joint probability distri- bution by maintaining the distribution parameters and θ unchanged. In this case, the posterior probability equals the variational distribution q. During the second step of maximization, the variational distribution q is fixed, and θ is optimized. When the variational distribution is not too complicated, the EM algorithm is very efficient in training. 2.3.4 Forms of variational inference Mean-field Assumption Measuring the mutual interaction between zi ∈ Z and z j≠i ∈ Z is difficult where Bayesian networks cannot represent the conditional probabilities. A classical assumption about variational inference is that the variational posterior distribution is an entirely decomposable distribution: m q(Z;φ) = ∏qi(zi) (2.11) i=1 where zi and z j≠i are independent and identically distributed. It ignores inference networks’ enrich structures, losing the variational distribution’s flexibility. One possible substitution is to add auxiliary variables as the conditions of φ in latent space. Based on this idea, many works sought to minimize the gap between true posteriors and approxi- mate posteriors, such as structured stochastic variational inference [23], inference with auxiliary variables [1], variational Gaussian process [66], Copula variational inference [65], and hierarchical variational models [55]. Gradient Descent Because the space of parameters and the space of distributions are different, stochastic gradient descent directly does not produce good results [24]. In order to improve SGD, the natural gradient stated in information geometry is used, and the so-called stochastic variational inference (SVI) is proposed [24]. The second- order derivative (Hessian) information is the essence of SVI. The SVI mainly discusses models with mean-field and conjugacy assumptions. The advantage of these models is that the Hessian is easy to calculate and has an explicit form, but for more complex models, calculating the Hessian will greatly increase the computational complexity of the algorithm. Pyro takes SVI as the main optimized methods [3]. Reparameterization Tricks We perform the gradient descent to the equation 2.6, which will lead to: ∇φELBO(x;θ,φ) = Eq(<a href="javascript:openDSC(614860630, 37, '115');" onmouseover="doRollover(84);" onmouseout="undoRollover(84);" id="115" name="84" style="color:brown" class="brown"><span class="b-ref">84</span>Z;φ<span>)[∇φlog(</span>q(Z;φ))log p<span>(qX(</span>Z,Z;φ</a>;)θ) ] (2.12) The stochastic gradient descent based on this equation is called <a href="javascript:openDSC(614860630, 37, '116');" onmouseover="doRollover(84);" onmouseout="undoRollover(84);" id="116" name="84" style="color:brown" class="brown"><span class="b-ref">84</span>Black Box Variational Inference (BBVI<span>) [53]. </span>The<span> problem </span>of</a> a high variance under the framework of BBVI is common. Using reparameterization tricks in latent space given by Max Welling’s variational auto-encoder (VAE) is proved to be efficient [29]. We assume that there exists a function Z = fφ(ε) where ε ∼ N (0, 1), then the equation 2.9 will become ∇φELBO(x;θ,φ) = Eε(∇φlog(p(X, fφ(ε)))−log(qφ(fφ(ε)))) (2.13) Recent works [29, 57] have proven that VAE can reduce variance and make the Monte Carlo estimation probable. But VAE also has apparent limitations: it can not deal with discrete variables, and the number of distribution groups to do reparameterization is limited. Two papers [27, 37] took the advantage of Gumbel-Softmax distribution to relax discrete variables then it is able to do reparameterization to discrete variables. Another problem with reparameterization is that the number of distributions that can do reparameterization is very limited. Automatic Differentiation Variational Inference (ADVI) [33] was proposed to map the variational <a href="javascript:openDSC(652896040, 37, '166');" onmouseover="doRollover(133);" onmouseout="undoRollover(133);" id="166" name="133" style="color:#935F32" class="#935F32"><span class="b-ref">133</span>distribution in the original<span> individual parameter </span>space to<span> an </span>unconstrained<span> common </span>space</a>. Blei et al. tried to use acceptance- rejection sampling to enlarge distributions used for reparameterization [45]. ADVI is the method that we will mainly discuss in this project. Flexible Transformations Variable transformation can be done in a more flexible manner. That is the point of normalizing flows (NFs) [57]. NFs are generalizations of the reparameterization trick: In the past, we transformed with a function, but now we can transform with a multi-layer function, as long as the Jacobian of the composite function is easy to solve. A key challenge at this point is to find enough representation power, and Jacobian is a family of functions that is more easily available. Research in this area has been extensive. A simple linear-time transformation was demonstrated [57], and it was also mentioned that infinite flows could be used, such as Langevin Flow and Hamiltonian Flow. Max Welling et al. proposed inverse autoregressive flows (IAFs) [30]. *Better Optimization Aims Given a main model, we need to design optimization objectives (such as KL divergence/ELBO), variational models, and corresponding optimization algorithms. Thus far, we have only discussed improvements in the latter two parts. Another optimization goal can be chosen in addition to ELBO. Compared to ELBO, importance-weighted auto-encoders (IWAE) [7] use a lower bound that is better. Additionally, operator variational inference (OPVI) [54] re-examines the design of this optimization objective and proposes a more general framework with KL loss. As a general matter, this type of problem is less work than the first two, since we can always design better optimization algorithms to compensate for the defects in the optimization goal. 2.4 Probabilistic Programming 2.4.1 Definition and Languages Programming paradigm of probabilistic nature is probabilistic programming (PP). Under this framework, the Bayesian probabilistic models are specified and inferred automatically [68]. The field of probabilistic programming combines machine learning, statistics, and programming languages, and develops evaluators for machine learning- based inference models [68]. In general, a probabilistic programming system provides researchers with direct answers when there is uncertainty about the parameters. Proba- bilistic reasoning hand-written programs can be used to assist in decision making under uncertainty. With probabilistic programming, such programs are more easily to imple- ment, providing a convenient framework or an interface to define the probability model as well as automatically learn probability models. By using probabilistic programming, researchers can avoid having to calculate the posterior based on their own models, or even write the parameter update process by hand. They can write their own programs quickly if they are familiar with a probabilistic programming language. Programming languages for probabilistic applications are commonly implemented using C, C++, Java, and Python, which are often extended from mainstream basic program- ming languages. For example, Alchemy [2] is extended by C++, Probabilistic-C [48] is extended by C, BLOG [41] is extended by Java and PyMC3 [61] is extended by Python. Different frameworks are used under different situations and domains, selecting the most appropriate language in accordance with the model descriptions and the environment settings, depending on personal preferences and easier implementations. Below we provide an overview of some mainstream probabilistic programming languages within the machine learning and statistics domain, [68], from which researchers can choose: • machine learning: Church [17], Anglican [70], BayesDB [39], CPProb [9] • statistics: Birch [44], STAN [8], Infer.NET [43] • deep generative models: Probtorch [62], Pyprob [35], Pyro [3] 2.4.2 Main PPL: Pyro Pyro [3], as described in part 2.4.2, is an open-source probabilistic programming framework available in Python and supported by PyTorch, an open-source machine learning library for researchers. Compared to other programming languages, it has the advantage of inferring for generative models and solving variational inference problems. Its torch-based API appeals to many users, as well. Although a new framework called NumPyro [52] has been released recently which is based on Jax for automatic differen- tiation (automatically compute gradients) and is faster than pyro, we introduce pyro instead to better understand how it is used for inference problems and not the advanced calculations for gradient optimization. A first step in Python is to construct your own dataset, or use a built-in dataset in Pyro. The next step is to construct your own model. It is possible to set some parameters of the prior distribution that are confirmed because one needs to know the prior distribution of the parameters first. Latent variables create new samples under the plate. In Pyro, the plate ensures conditional independence between new data. Designing the guide is the third step. The variational distribution in pyro is called guide, and it is only determined by the latent variables, so we only need to create <a href="javascript:openDSC(49066003, 917, '175');" onmouseover="doRollover(142);" onmouseout="undoRollover(142);" id="175" name="142" style="color:#287B28" class="#287B28"><span class="b-ref">142</span>the joint probability distribution<span> among </span>all<span> latent </span>variables<span>. The fourth step </span>is</a> to identify our optimizer, usually Adam, but it can also be SGD. The final step is to bring the model and guide into SVI (stochastic variational inference). The ELBO parameters’ update is automatically calculated by SVI in Pyro. It will calculate KL loss when using the step function. We can then train the model to figure out the latent variables’ parameters. Consequently, by comparing the prior to get a better posterior probability that matches the input data as a knowledge, we can generate more data according to the model to see if the posterior is better than the prior. This is the general framework for training in Pyro, which demonstrates that a reasonable posterior, one dataset, and only one model are needed. Some scholars might still feel that designing a suitable guide is difficult, and hope that the program can guides the model automatically on its own. Fortunately, Pyro has already provided these guides, where the base is called AutoGuide. The aim of this project is to generate new autoguides or improve the original autoguide to make the variational distribution closer to the ideal posterior distribution. In Pyro, we mainly concern ourselves with the classes AutoGuide, AutoContinuous and some of their inheritance, including Mean-field Gaussian posterior AutoDiagonalNormal and Full-Rank Gaussian posterior AutoMultivariateNormal. With regard to an example, here we are demonstrating: 1 from pyro.infer.autoguide import AutoDiagonalNormal 2 from pyro.infer.svi import SVI 3 guide1 = AutoDiagonalNormal(model) # Mean-field 4 svi = SVI(model , guide1 , ...) # Stochastic Variational Inference 5 for i in len(num_steps): 6 loss = svi.step(x, y) # record loss Listing 2.1: Example of using Pyro AutoGuide Pyro has provided the function get param store() to extract the learned parameters, allowing us to plot the data given the posterior distribution and model parameters. The performance of mean-field and full-rank Gaussian distributions can be improved by providing new classes and using them as shown in the code block. The details of building new models in Pyro will be explained in part 3.4. 2.5 Bayesian Networks (BN) 2.5.1 Definition A graphical model (PGM) represents the structure of conditional dependencies between random variables with a graph. The model is commonly used in Bayesian inference and probability theory. There are three types of probabilistic graphical models: Undirected Graphical Model (DG) , Directed Acyclic Graphical Model (DAG) and Directed Cyclic Graphical Model (DCG) [32].A Bayesian Network (BN) is equivalent to a DAG, where edges are directed and its <a href="javascript:openDSC(642235957, 3796, '24');" onmouseover="doRollover(22);" onmouseout="undoRollover(22);" id="24" name="22" style="color:#287B28" class="#287B28"><span class="b-ref">22</span>joint probability can be<span> expressed </span>as a<span> multiplication </span>of conditional probabilities</a>. We care about BN only, since we intend to explore inverse dependencies of models, which is an indication that the model needs to be directed and acyclic. Two commonly known examples about Bayesian Networks are: Deep Belief Networks [21] and Gaussian Mixture Model [56]. 2.5.2 Important Properties of BN We have discussed in this section how the BN is related to a probability distribution, what its essential properties are, and how it is used in our project. Factorization The general expression of a joint probabilityforaBNG(V,E)is: x1 p(x)= ∏ p(xv|xpa(v)) (2.14) v∈V x2 x3 We give an example to illustrate the construc- <a href="javascript:openDSC(666085429, 37, '83');" onmouseover="doRollover(58);" onmouseout="undoRollover(58);" id="83" name="58" style="color:#cc0066" class="#cc0066"><span class="b-ref">58</span>x 4 x 5 x 6</a> tion of a joint probability of Bayesian Network, also called the factorization process. Given a Figure 2.1: An example <a href="javascript:openDSC(697208274, 2474, '153');" onmouseover="doRollover(120);" onmouseout="undoRollover(120);" id="153" name="120" style="color:#336699" class="#336699"><span class="b-ref">120</span>of a graph G(V ,E), where V<span> = {x1,x2,...,x6} </span>and</a> Bayesian Network: G(V ,E), E = {<a href="javascript:openDSC(358029724, 43, '129');" onmouseover="doRollover(96);" onmouseout="undoRollover(96);" id="129" name="96" style="color:#63009c" class="#63009c"><span class="b-ref">96</span>x1 → x2,x1 → x3,x2 → x4,x2 → x5,x3<span> → where V = {</span>x1,x2<span>,...,x6} and x5,</span>x3 → x6</a>}, as shown in Figure 2.1. The ob- E = {<a href="javascript:openDSC(178872, 37, '176');" onmouseover="doRollover(143);" onmouseout="undoRollover(143);" id="176" name="143" style="color:blue" class="blue"><span class="b-ref">143</span>x1 → x2,x1 → x3,x2<span> → servation of </span>x2</a> depends on the observation of x1, x4,x2 → x5,x3 → x5,x3 → x6} indicating that <a href="javascript:openDSC(11933709, 37, '177');" onmouseover="doRollover(144);" onmouseout="undoRollover(144);" id="177" name="144" style="color:brown" class="brown"><span class="b-ref">144</span>x1 is<span> the </span>parent of x2<span> so </span>the</a> joint probability of <a href="javascript:openDSC(41388423, 2, '136');" onmouseover="doRollover(103);" onmouseout="undoRollover(103);" id="136" name="103" style="color:blue" class="blue"><span class="b-ref">103</span>p(x1,x2) = p(x1)p(x2<span>|x1). </span>The<span> joint </span>probability of<span> the total graph </span>is</a>: <a href="javascript:openDSC(1984396773, 304, '101');" onmouseover="doRollover(70);" onmouseout="undoRollover(70);" id="101" name="70" style="color:#CB0099" class="#CB0099"><span class="b-ref">70</span>p(x1<span>, x2, ..., </span>x6) = p(x6<span>|x3)</span>p(x5|x2, x3)p(x4|x2)p(x3|x1)p(x2|x1)p(x1</a>) (2.15) The inverse conditional probability is a posterior distribution. Now x4, x5, and x6 are latent nodes and x1 is the observed node. Therefore, it is an inference problem. Due to the fact that inference cannot be induced directly, it is necessary to assume an inverse dependency, reconstructing observed latent nodes from unobserved ones. Methods of analyzing a model’s inversed dependency structure will be discussed in part 3. Local Markov property Based on its parent variables, the local <a href="javascript:openDSC(49066170, 917, '127');" onmouseover="doRollover(94);" onmouseout="undoRollover(94);" id="127" name="94" style="color:#ce0031" class="#ce0031"><span class="b-ref">94</span>Markov property states that each variable is independent of its non-descendent variables</a>: <a href="javascript:openDSC(3967227253, 3791, '146');" onmouseover="doRollover(113);" onmouseout="undoRollover(113);" id="146" name="113" style="color:#935F32" class="#935F32"><span class="b-ref">113</span>Xv ⊥ XV∖de(v)|Xpa(v) for all v<span> in </span>V</a> (2.16) We can use this condition to remove redundant variables in calculating joint probability. d-separation and I-map Based on a third set Z, d-separation determines whether a particular set of variables X is independent from a different set Y on a Bayesian network. Local Markov property is a particular case of d-separation. If any node in the trail between A and B is not observed and the trail is converging, then node A and node B are d-separated. The easiest way is to perform the moralization of graphs and remove observed variables to see if an edge is added between node A and node B. More examples are presented in Koller’s PGM book [32]. Graphs that satisfy all the conditions of an independent distribution are called I-maps, where the conditional independence contained in the graph is a subset of the conditional independence satisfied by the distribution. A distribution can be derived from a list of graphs that includes all dependencies, which allows us to assume less distribution at a time. 2.5.3 BN with Variational Inference A plate model describes the dependencies between variables in a Bayesian network. The plate model eliminates the need to account for the interdependencies of each variable in the group. In addition to presenting variational inference in a Bayesian network, the plate model can differentiate <a href="javascript:openDSC(737654154, 917, '64');" onmouseover="doRollover(47);" onmouseout="undoRollover(47);" id="64" name="47" style="color:#0270B6" class="#0270B6"><span class="b-ref">47</span>between the conditional prior<span> probability distribution </span>and the posterior<span> distribution. θ </span>z<span> z </span>φ</a> x <a href="javascript:openDSC(737654154, 917, '65');" onmouseover="doRollover(47);" onmouseout="undoRollover(47);" id="65" name="47" style="color:#0270B6" class="#0270B6"><span class="b-ref">47</span>x N N Figure 2.2<span>: Plate </span>model of</a> pθ(z)pθ(x|z) Figure 2.3: Plate model of qφ(z|x) θ is the shared parameter for computing prior and conditional probability based on Z and X and is none of the observed and latent variables, so it’s out of the plate. Computing posterior is the opposite process which is directed from X to Z. In the approximation space, φ is the only parameter to Z. In general, we build a plate model to see dependencies of variational inference clearly. Chapter 3 ADVI and potential improvements This chapter attempts to explain the methodology used in the experiments in terms of theories that could improve basic variational methods and autoguides. Section 3.1 describes the inference problem to be solved. Section 3.2 presents ADVI, one of the most effective solutions to the central problem based on variational inference. Section 3.3 presents improved methods of estimating the posterior by accumulating the inverse dependency of the latent variables. In Section 3.4, we present novel methods of improving autoguides by using different types of covariance matrices, where Gaussian distributions dominate the approximation space. The third improvement method called inference compilation, is discussed in Section 3.5. 3.1 Problem Restatement In the previous paragraph, the concept and nature of the inference problem were discussed. Here is a recap of the problem and below we will provide a solution. In essence, one central issue of this essay <a href="javascript:openDSC(330578173, 3265, '49');" onmouseover="doRollover(40);" onmouseout="undoRollover(40);" id="49" name="40" style="color:#336699" class="#336699"><span class="b-ref">40</span>is to<span> determine </span>the posterior distribution of latent variables given</a> any custom probability model containing <a href="javascript:openDSC(1019486955, 3722, '91');" onmouseover="doRollover(62);" onmouseout="undoRollover(62);" id="91" name="62" style="color:#287B28" class="#287B28"><span class="b-ref">62</span>latent variables, the<span> prior distribution </span>of<span> these </span>latent variables and the</a> data points. By finding a more accurate posterior distribution, some unknown data <a href="javascript:openDSC(138769303, 3797, '111');" onmouseover="doRollover(80);" onmouseout="undoRollover(80);" id="111" name="80" style="color:#336699" class="#336699"><span class="b-ref">80</span>points can be<span> predicted </span>from the<span> pattern of </span>the latent variables<span>. In section 2, </span>the</a> inference problem has been formulated. One example here is that the problem can be pertained to solve Gaussian posterior distributions. As far as the one- dimensional Gaussian distribution is concerned, mean and variance are latent variables (scalars). For the multivariate Gaussian distribution, mean vectors and covariance matrices are <a href="javascript:openDSC(817894665, 3796, '170');" onmouseover="doRollover(137);" onmouseout="undoRollover(137);" id="170" name="137" style="color:#A85503" class="#A85503"><span class="b-ref">137</span>latent variables. In<span> general, </span>the posterior distribution of the</a> Gaussian <a href="javascript:openDSC(616812302, 37, '78');" onmouseover="doRollover(55);" onmouseout="undoRollover(55);" id="78" name="55" style="color:#866712" class="#866712"><span class="b-ref">55</span>distribution is in the same distribution<span> group </span>as the prior<span> distribution, which </span>is<span> known as </span>a conjugate prior</a>. A posterior with such priors has an analytical solution when they are converted. In other words, under the denominator of Bayes theorem formula 2.1, the integral of the observed variable is also generally integrable. As with the posterior and prior, the gamma <a href="javascript:openDSC(4167210596, 3722, '173');" onmouseover="doRollover(140);" onmouseout="undoRollover(140);" id="173" name="140" style="color:#336699" class="#336699"><span class="b-ref">140</span>distribution and the<span> beta </span>distribution are conjugate<span> as well. </span>For<span> discrete variables, </span>the</a> classic conjugate priors are the multinomial 14 prior, poisson prior, and bernoulli distribution. It is generally necessary to map a one- dimensional integral to a high-dimensional integral for MCMC with Gibbs sampling if the denominator integral cannot be calculated for any other discrete or continuous variable distribution. This greatly increases the time and space complexity of the calculation. Ideally, we would like to keep away from the time-consuming process of integrating or sampling. In this way, we introduce a variational distribution, in which variational clusters reduce the distance from the original posterior distribution. Data points are not considered in the estimation as they do not influence the parameters of the variational distribution. The method does, however, have some obvious restrictions. In some cases, it is impossible to determine what the true posterior distribution is, making it impossible to decide on a variational factor that is reasonable. A second problem is that its variables have constraints on their distributions and ranges. It follows that the variables of the variational distribution will be strictly within the same distribution cluster as the parameters of the posterior and prior distribution. During the maximization of expectations process (EM), the variational distribution q is optimized, as outlined in section 2. During this process, KL divergence will also be calculated so that the gradient of ELBO will be calculated automatically. It will be necessary to make sure that the parameter value is still within that limited range after the gradient update. Therefore, it is crucial to always be aware of the parameter value’s size in order to avoid the update parameter running over the set limit. This process requires experts and humans to predetermine the parameters. Depending on the model and the data, there will be different parameters and range settings, which can be very troublesome, since setting parameters can’t be generalized. In order to ensure that any model can use the same parameter space, a new method is introduced in which all latent variables, regardless of distribution, are reparameterized into a high-dimensional space. ADVI discusses this method extensively. Detailed discussion of ADVI, including further approximations to latent distributions, is provided in section 3.2. 3.2 ADVI The ADVI process consists of four stages: 1) remap each input’s parameter distribution into a new shared space, remove restrictions on its values 2) approximate the shared space to a Gaussian distribution 3) transform into a standard normal for automatic differentiation and Monte Carlo integration 4) specify parameters (latent variable) update based on Monte Carlo sampling and gradient descent. ADVI requires no conjugate prior, but only a differentiable variable distribution, since the gradient must be continuous. In addition, the input model should also be differen- tiable, and the joint probability distribution type should support the priority. The authors have mentioned a number of models that were used for testing autoguides, including linear regression, GMMs, and LDAs [33] , which can marginalize out variables to ensure that they meet the continuous and differentiable conditions. 1) Given Latent variables θ, and its prior distribution: p(θ). The aim is to transform the support of θ in order to be live in RK space Q by function T. The transformed joint distribution <a href="javascript:openDSC(145346898, 3793, '60');" onmouseover="doRollover(45);" onmouseout="undoRollover(45);" id="60" name="45" style="color:#B64B01" class="#B64B01"><span class="b-ref">45</span>can be expressed as: p<span>(x,</span>q) = p(x<span>,T−1(</span>q</a>)) | detJT−1(q) | (3.1) where p(x,T−1(q)) represents the original distribution factor <a href="javascript:openDSC(2501470696, 3797, '138');" onmouseover="doRollover(105);" onmouseout="undoRollover(105);" id="138" name="105" style="color:#B64B01" class="#B64B01"><span class="b-ref">105</span>and JT−1 is the Jacobian<span> matrix </span>of the inverse of T</a> [47]. An example is the Gaussian distribution where its covariance matrix is diagonal. To ensure that the diagonal of its covariance matrix is positive, the values on the diagonal must be greater than 0, which is identical to the determinant of the covariance matrix | diag(σ2)| &gt; 0. Afterward, you can alter θ into the real number domain either by using the softplus function log(1+e(σ2)), or by directly using the log function. 2) Any given transformed parameter can be approximated to this space by a common distribution group, which is defined as a Gaussian distribution in ADVI. The following two cases should be discussed in this context. The first case is to assume that the latent variables in the Q space are independent of each other, which is the so-called mean-field Gaussian distribution with factorization separated: q(η,Θ) = Normal(η | µ,diag(σ2)) (3.2) = ∏Normal(ηk | µk,σk2) K (3.3) i=1 where Θ = {µ1, ..., µk} ∪ {σ21, ..., σ2k}. In the Pyro implementation, each of the variables is concatenated with each other and will lead to a R2K vector. Obviously the variances have been constrained to the positive real coordinates, therefore we should remove this constraint by mapping these positive variance to the whole real number space, where the function might be a softplus function or just a simple logarithm transformation. One problem of this method is that we assume the variables are independent of each other, but actually latent variables might include some dependencies between each other where we need to accmulate these dependency distribution to reach a joint distribution. So a multivariate normal distribution is needed. It is also called full-rank Gaussian, since each row or column entry of a covariance matrix is not a combination or other row or column vectors in the matrix. Likewise, the form of <a href="javascript:openDSC(638760039, 3160, '161');" onmouseover="doRollover(128);" onmouseout="undoRollover(128);" id="161" name="128" style="color:#330099" class="#330099"><span class="b-ref">128</span>the full-rank approximation is<span> in this form: </span>q<span>(η;</span>Θ<span>) = Normal(</span>η</a> | µ,∑) (3.4) We must make sure that ∑ should be also positive semi-definite as definition of the covariance matrix. Therefore, we could use a special LU factorization: Cholesky factorization which assumes that ∑ = LLT and that covariance matrix is positive defintie. Only one factorization for a positive definite and symmetric matrix exists. It can help explain the fact that dependence between each pair of two variables might help improve the posterior distribution, while it could include more parameters to train than a mean- field assumed distribution and still requires a cholesky constraint for the covariance matrix. The number of parameters to train in a mean-field Gaussian is equal to 2*K, <a href="javascript:openDSC(1019486955, 3722, '92');" onmouseover="doRollover(62);" onmouseout="undoRollover(62);" id="92" name="62" style="color:#287B28" class="#287B28"><span class="b-ref">62</span>where K is the<span> latent dimension (</span>number of<span> variables), but </span>the number of</a> parameters to train in a full-rank Gaussian is equal to K+K*(K+1)/2. 3) We need to revisit the loss function for estimating the best q function in the trans- formed Q space, which is shown in background part that the metrics to measure two distribution’s differences is <a href="javascript:openDSC(3275918589, 3783, '31');" onmouseover="doRollover(27);" onmouseout="undoRollover(27);" id="31" name="27" style="color:#0270B6" class="#0270B6"><span class="b-ref">27</span>the KL-divergence<span> Loss and </span>is equivalent to<span> measuring </span>the ELBO</a>. However, in the transformed space, we need to rewrite it to be related with q function and the common parameters Θ in the Q space, which is: L(Θ) = Eq(η;Θ) [l og q(η; Θ) p(x; θ) ] (3.5) = Eq(η;Θ) [l og p x, T −1 (η) + l og|d et JT −1 (η) |] + H[q(η; Θ)] (3.6) It is intractable to calculate the expected differential for the ELBO when updating it and ( ) doing back propagation. Thus, we can calculate the differentiation of the term inside the expectation first, and then find the expectation by applying the final transformation, which is called the elliptical standardization [28]. Sθ can be regarded as a transformation that encapsulates the variational parameters in the latent space. This will convert the non- standard Gaussian distribution into a standard Gaussian distribution. The transformation for the mean-field assumption is ζ = Sθ(η) = <a href="javascript:openDSC(330578173, 3265, '50');" onmouseover="doRollover(40);" onmouseout="undoRollover(40);" id="50" name="40" style="color:#336699" class="#336699"><span class="b-ref">40</span>diag(exp(w))−1<span>(η−</span>µ<span>) , but for </span>the full- rank<span> assumption, it </span>is<span> ζ = Sθ(</span>η</a>) = L−1(η−µ). As a result, it will generally lead to an approximation of the standard normal: q(ζ) = N ormal (ζ|0, I ). As entropy is independent of both the model and the transformation, it does not require transformation. It is also stated that <a href="javascript:openDSC(330578173, 3265, '51');" onmouseover="doRollover(40);" onmouseout="undoRollover(40);" id="51" name="40" style="color:#336699" class="#336699"><span class="b-ref">40</span>a simple analytic form<span> is given </span>for the entropy of<span> the Guassian </span>and its gradient</a>, which can be implemented once and reused for all other models [33]. Algorithm 1 Parameter updating process for ADVI [33] Require: Dataset x, model p(x;θ), iteration i = 1, threshold δ µ1 = 0, w1 = 0 (mean-field) and L1 = 0 (full-rank) while ∇ELBO less than δ <a href="javascript:openDSC(330578173, 3265, '52');" onmouseover="doRollover(40);" onmouseout="undoRollover(40);" id="52" name="40" style="color:#336699" class="#336699"><span class="b-ref">40</span>do Draw M samples<span> ζm ∼ </span>Normal(0, I<span>) Approximate </span>the</a> gradient to the mean ∇µL using MC integration Approximate the gradient to the covariance ∇wL or ∇LL using MC integration Calculate the current step size ρi Update µi+1 ⇐ µi + diag( ρi) ∇µL Update wi+1 ⇐ wi + diag( ρi) ∇wL Update Li+1 ⇐ Li + diag( ρi) ∇LL Increment iteration counter i = i + 1 end while Return µ∗ ⇐ µi Return w∗ ⇐ wi Return L∗ ⇐ Li 4) As a final step in ADVI, the update of the variational distribution parameters plays a significant role. Since we approximate the variational distribution as a Gaussian score, there is a parameter of µ regardless of whether it is the mean-field assumption or the full rank assumption. To conclude, the rest parameters associated with the mean-field assumption are w, while the parameters associated with the full rank assumption are L. If we separately differentiate these three variables, we will get ∇µL, ∇wL and ∇LL. As a result of approximate standard normalization of the terms within the expectation, they are now differentiable, so the expectation is the only thing left to do. Monte Carlo Integration can therefore be applied to draw samples based on the standard normal. In some conditions, the algorithm converges to the ELBO local maximum. The algorithm is implemented in one class called AutoGuide in Pyro. Two assumptions AutoNormal and AutoMultivariateNormal are derived from AutoGuide. They are the most basic type of autoguides and we compare them with our novel autoguides. 3.3 Learning Inverse Dependencies Although ADVI successfully maps the parameters of any model into the same latent space, the algorithm assumes independence between variables. We hope that by incorpo- rating the <a href="javascript:openDSC(404333048, 3796, '169');" onmouseover="doRollover(136);" onmouseout="undoRollover(136);" id="169" name="136" style="color:#63009c" class="#63009c"><span class="b-ref">136</span>conditional distribution<span> between </span>the latent variables<span> into </span>the<span> calculation of </span>the posterior</a> probability, we can fully take advantage of the dependencies between variables to infer parameters. In part 2, we discussed how the original probability from a latent variable node to an observed node <a href="javascript:openDSC(7722169, 37, '150');" onmouseover="doRollover(117);" onmouseout="undoRollover(117);" id="150" name="117" style="color:#A85503" class="#A85503"><span class="b-ref">117</span>can be represented<span> as </span>a<span> probabilistic </span>graphical model<span>. In contrast, for </span>the<span> calculation </span>of the</a> posterior probability, it must be done by creating a reverse probabilistic graphical model from the observed node (or leaf node) to the latent node. The reverse probability model must be constructed by first converting the directed graph into an undirected graph [60], which we can then construct the posterior from the moralized graph. It maximizes the expression of the original information about the original paths in the graph. It minimizes the loss of the conditional independence that is contained in the directed graph. Moralization and Markov Blanket As moralization is not the main point of the project, it serves as a prerequisite for inverting the models, so I will simply explain how it works here. By using a moral graph in graph theory, a directed acyclic graph can be translated into its equivalent undirected form. For the junction tree algorithm, it is one the most important step, which is used to propagate beliefs on graphical models. An undirected equivalent of a directed acyclic graph is formed by enforcing <a href="javascript:openDSC(570104602, 37, '88');" onmouseover="doRollover(60);" onmouseout="undoRollover(60);" id="88" name="60" style="color:#336699" class="#336699"><span class="b-ref">60</span>edges between<span> all </span>pairs of<span> nonadjacent nodes </span>that<span> have </span>a common child, and then<span> removing </span>all<span> direct </span>edges</a> from the graph. In equivalent terms, an undirected graph is a moral graph of <a href="javascript:openDSC(570104602, 37, '89');" onmouseover="doRollover(60);" onmouseout="undoRollover(60);" id="89" name="60" style="color:#336699" class="#336699"><span class="b-ref">60</span>an acyclic directed graph<span> in which </span>the<span> nodes </span>of the</a> original G are now connected to their Markov blankets. In a trusted Bayesian network, a Markov blanket of node A <a href="javascript:openDSC(138774748, 3797, '112');" onmouseover="doRollover(81);" onmouseout="undoRollover(81);" id="112" name="81" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">81</span>refers to a set of<span> nodes </span>related to<span> A ,which contains </span>the<span> nodes </span>of</a> A’s parents, its children, and its child nodes’ parents (excluding A). In a Markov random field, a Markov blanket is simply represented as a node adjacent to node A. A Markov blanket usually represents the first case in machine learning. At this point, we can compute the moral graph for any directed acyclic graphical model. Example As a simple example, figure 3.1 on the left shows a DAC in which C is a latent node. It has nodes A and B as parents. E is a child node. D is the parent node of child node E apart from node C. Based on the definition of moralization, the parent node of C shares a child node. However, the parent node does not have a link. Therefore, we need to add an edge between A and B to indicate the relationship between A and B. Similarly, another edge needs to be added between C and D, so two operations are Figure 3.1: A directed acyclic graph and its moral graph [24] Figure 3.2: A moral graph and its reverse graph of 3.1 left [24] performed in this graph. When it comes to C’s Markov blanket, it is the parent node of C, which are A and B, the child node E of C, and the parent node D of the child node of C. In other words, node C’s markov blanket is all nodes except C. The inverse dependency of the model can be obtained in two ways. Starting from the observed node and upstreaming to the latent node is the first method. In this method, the node distance between an observed node and current node is measured and topological sorting or shortest distance sorting is performed. Starting from the latent node, the second method proceeds down in a downstreaming process. To calculate joint probability distributions, the metrics are used <a href="javascript:openDSC(703945590, 917, '163');" onmouseover="doRollover(130);" onmouseout="undoRollover(130);" id="163" name="130" style="color:#CB0099" class="#CB0099"><span class="b-ref">130</span>to determine the<span> minimum </span>number of<span> variables </span>needed to<span> eliminate </span>the</a> variables. Alternatively, we are considering the smallest number of additional edges required to form the smallest clique for a node which will be the parent (or root) of the reverse model. 3.3.1 Observed to latent (Upstream) Analyzing from observed data to latent variables is mentioned in two articles [49, 63]. In <a href="javascript:openDSC(2144471675, 3265, '125');" onmouseover="doRollover(92);" onmouseout="undoRollover(92);" id="125" name="92" style="color:#795AB9" class="#795AB9"><span class="b-ref">92</span>a directed graph G(V ,E), V and E represent the vertices and edges</a>, respectively. And given the observed node vobs, then any vk in V except vobs has a distance from vobs, which is expressed as: dist(vobs, vk). We can sort all points in V using this distance metric. In this list, the most frontal node is the one closest to the observed nodes. In order to maintain the conditional probability, we connect all points except the parent nodes in the original forward diagram to the current point. Based on the above explanation of d-separation, the point and all the other unconnected points in the graph are independent of one another. We will proceed to the next node in the list after that until we have explored all latent variables. With respect to Figure 3.1, we will begin with E, where E is the observed node. Ac- cording to the moral graph, the original E’s parents C and D become its children in the reverse graph. Distance from E to C and D is the same, i.e. dist(C,E) = dist(D,E). The distance between D and A is now equal to infinity since A is a leaf node and there is no path from D to A. D is ranked before C because D is more distant from the leaf node whereas the distance between A and C is 1. We add a directed edge VC′→D , and similarly add VA′→B . The implemented algorithm arranges the nodes either in topological order or according to their distance from the observed node. First, the inverse dependency of the original priority is added, followed by a directed edge from the markov blanket (excluding its parents in original fowarding graph) to the node according to the order of the order, with the directed edge pointing to the node. In the papers relating to the two methods, two distinct sampling methods were dis- cussed. In order to perform online forward and reverse sampling in stochastic inverse, the MCMC and MH sampling algorithms are used [63]. The second method involves simplifying the inverse graph to produce distinct latent variable(s) by using its connec- tion relationship as a basis [49]. The <a href="javascript:openDSC(617022268, 37, '80');" onmouseover="doRollover(56);" onmouseout="undoRollover(56);" id="80" name="56" style="color:#63009c" class="#63009c"><span class="b-ref">56</span>model is<span> regarded </span>as a forward<span> neural </span>network. To<span> learn </span>the</a> revised conditional density, sequential Monte Carlo is employed [49]. New sampling methods were not considered in this study. In contrast, we examined whether adding such inverse dependency would improve inference effects. 3.3.2 Latent to observed (Downstream) Figure 3.3: A DAG with 7 nodes. First moralize the graph, which means additional edges should be added between A and B, D and E, and C and G [69]. Figure 3.4: Start with latent node, A and B. For B, we need to add another edge CD and AD to calculate the joint probability <a href="javascript:openDSC(410765885, 3796, '144');" onmouseover="doRollover(111);" onmouseout="undoRollover(111);" id="144" name="111" style="color:#006331" class="#006331"><span class="b-ref">111</span>p(A, B, C, D<span>), so </span>A<span> is prior than </span>B<span> since calculating </span>p(A<span>, B, </span>C</a>) does not require adding any edge in the graph [69]. Another method explores the inverse dependency structure from latent nodes to observed nodes [69]. In essence, a directed graph is constructed from the latent nodes to the observed nodes. Examples are given in figures 3.3 through 3.8. We begin by constructing the list of nodes that have been visited already (null), followed by the list of frontier variables that are ready for elimination. In 3.3, we reach a moral graph of the left DAG. Figure 3.5: After A is eliminated and marked as visited, since B is not visited so we need to visit B. We need to calculate the joint probability p(B, C, D). Therefore, an edge CD is added. C and D are added to the latent node list and B is removed from the list [69]. Figure 3.6: Similarly, eliminating D does not require adding any edges (edge CD has already been added in the last round), so D is prior than C [69]. Figure 3.7: Eliminating C requires adding an additional edge EF. After that, add E to the latent node list. E is the last node to eliminate since F and G are observed nodes (roots) [69]. Figure 3.8: Finish traversing and the directed graph on the right is the inverse dependency graph of the original model (posterior) [69]. Latent nodes A and B are referred to as frontier variables. If we wish to eliminate joint probability p(A, B, C), we must form a minimal clique with A’s neighbors B and C. Checking B reveals that eliminating p(A, B, C, D) does require an additional edge between C and D. This means there are no ACD or BAD cliques, so A is more prior than B. Afterward, A is selected with its neighbors pointed to it, and A is then marked as visited. Since B is still in the frontier variable list, visit B. To eliminate <a href="javascript:openDSC(135745519, 3793, '70');" onmouseover="doRollover(49);" onmouseout="undoRollover(49);" id="70" name="49" style="color:#227967" class="#227967"><span class="b-ref">49</span>p(A, B, C, D<span>), two variables C </span>and</a> D are needed, so C and D are added to the frontier variables list. We repeat the above process until we reach the last observed node. Finally, directed edges are added from observed nodes to the last observed node. We can also express this algorithm this way: we sort nodes according to the number of variables to be eliminated, then add edges between Markov blankets (between nodes). This algorithm has been implemented in Pyro which is called AutoStructured. 3.4 Covariance Matrices’ Variants We discovered improvements to autoguide by passing covariance matrices, in addition to inverting model dependencies. We wonder, for example, if we can use methods other than softplus constraints to make the variance and mean always greater than 0, for the class of AutoDiagonalNormal (corresponding to the mean-field assumption in ADVI). AutoMultivariateNormal is another example. To ensure positive definiteness of the covariance matrix, we only use the lower triangular matrix for this class (corresponding to the full-rank assumption in ADVI) and pass it as the scale tril to the Gaussian <a href="javascript:openDSC(147331460, 3793, '39');" onmouseover="doRollover(34);" onmouseout="undoRollover(34);" id="39" name="34" style="color:#ce0031" class="#ce0031"><span class="b-ref">34</span>distribution. To reduce the number of parameters<span> or improve inference, </span>we</a> considered designing different covariance matrices. Six new autoguides were designed using different covariance matrices, with the only condition being that the covariance matrix must always be positive definite. 3.4.1 PolyDiagNorm We observe from the class AutoNormal or AutoDiagonalNormal that the posterior distribution obeys the rule that the scale term should be transformed by a softplus function to ensure that each variance term in the scale vector is positive. The main idea for the new autoguide PolyDiagNorm is to perform linear transformation to each term in the scale. Given a scale x = [x1, x2, ..., xn], looking from the intermediate results of any sampled training in our tested datasets, any trained xi would not be larger than 10 for example. More strictly, since the original scale was assigned to a small value so it’s not likely to show big gradient jump in the training. Therefore, 0.1 * xi will be smaller than 1. Recall the theorem that: 1 1−x = 1 + x + x2 + ... + xn (3.7) for any x within -1 to 1 where n is close to infinity. Given any n, the value <a href="javascript:openDSC(677743980, 917, '160');" onmouseover="doRollover(127);" onmouseout="undoRollover(127);" id="160" name="127" style="color:#0270B6" class="#0270B6"><span class="b-ref">127</span>on the right side of<span> the </span>equation will be</a> larger than zero. Therefore we can define a function F(x) = 1 + x + x2 for example, the new scale that is passed to the distribution function will become: x’ = [F(x1), F(x2), ..., F(xn)], where each term in x’ is larger than zero and thus removing the softplus constraints. With a high-dimensional dataset, we can set the coefficient of xi to a smaller value, which may be task-specific. It is conceivable that there is a better way to remove constraints, such as assigning a sine or cosine function to the original value, which is considered to be included in our future work. 3.4.2 SymmetricNorm In the AutoMultivariateNormal class, cholesky factorization has been performed, and the results have been passed to scale tril so that they satisfy the full-rank assumption in ADVI. We find that the matrix scale tril is a lower triangular matrix. The disadvantage is that it still requires a lot of parameters during the training process. In addition, we want to investigate how to generate new types of positive definite covariance matrices without cholesky factorization. In order to generate the symmetric matrix, we perform a matrix-level multiplication with the scale vector and its transpose. Suppose that the latent dimension is N. Then the total parameters for training in AutoMultivariateNormal is equal to N*(N-1)/2. <a href="javascript:openDSC(2464121755, 3796, '118');" onmouseover="doRollover(86);" onmouseout="undoRollover(86);" id="118" name="86" style="color:#630000" class="#630000"><span class="b-ref">86</span>In our method<span> SymmetricNorm, </span>the number of parameters is</a> still 2*N. According to the symmetric matrix theorem, given any matrix or vector x, xxT is symmetric. It is easy to prove that (xxT )T = (xT )T xT = xxT so that the matrix is symmetric. Then we scale the matrix by a small number c, such as 0.01. From linear algebra, we know that adding a few small elements to the diagonal of a symmetric matrix can make it positive definite. Therefore our covariance matrix Cov will become: Cov = c ∗ xxT + K ∗ In (3.8) where n is the latent dimension (dim) and x ∈ R1∗dim. Typically c is equal to 0.01 and K is equal to 1. We could also perform matrix decomposition to this positive definite matrix to extract its eigenvalues which can be further transformed into a diagonal matrix, where Cov = U ∑U T , where U T = U −1 and ∑ is a diagonal matrix containing Cov’s eigenvalues. We can pass ∑ to covariance matrix since eigenvalues for a positive definite matrix are larger than zero, but it is our choice whether or not to do so. 3.4.3 LowRankNorm Our new autoguide LowRankNorm is a special case of SymmetricNorm. Suppose that we would like to create a covariance matrix by a low-rank matrix Cov, where Cov ∈ <a href="javascript:openDSC(713398793, 37, '159');" onmouseover="doRollover(126);" onmouseout="undoRollover(126);" id="159" name="126" style="color:#630000" class="#630000"><span class="b-ref">126</span>R m∗n and m ≠ n. The<span> implementation </span>of</a> the class AutoLowRankMultivariateNormal entails self-multiplicating Cov with the transpose of Cov’s diagonal and adding small numbers to it along with Cholesky factorization. It may have disadvantages, such as adding squared scales to the diagonals instead of a unified scaled identity matrix, and it does not account for the scaling fact of Cov.CovT . The idea is to multiply Cov by another trained matrix and add a scaled number c: Cov′ = c ∗ (U · Cov)(U · Cov)T + K ∗ In (3.9) where U ∈ Rn∗m. c is typically equal to 0.01 and K is equal to 1. Moreover, Cov’ may be substituted into equation 3.8 to make it the case of SymmetricNorm. 3.4.4 BlockDiagNorm The block diagonal matrix, for instance, is one of the useful but special types of matrix in linear algebra. We create the autoguide BlockDiagNorm based on the block diagonal matrix. This type of matrix is square diagonal matrices that have square elements on the diagonal while containing zeroes on the off diagonal. The block diagonal matrix C is typically in this form: A 0 · · · 0 C = ⎛ 0 B · · · 0 . ⎞ . . . . 0 where A, B..., K could be any kind ⎝of matrix. There ⎠is only one requirement: C must ⎜ 0 · · · · · · K ⎟ have the same number of rows and columns. We only used two matrices A and B to construct such C in the real implementation. Therefore, both A and B must be positive definite in order for this block diagonal matrix to be positive definite. We use the same operations as described in 3.4.2 and 3.4.3. It also cuts down the number of parameters for training, since A ∈ <a href="javascript:openDSC(2593604128, 2909, '155');" onmouseover="doRollover(122);" onmouseout="undoRollover(122);" id="155" name="122" style="color:#287B28" class="#287B28"><span class="b-ref">122</span>R⌈N<span>/2⌉∗⌈</span>N/2⌉ and<span> B ∈ R⌊</span>N<span>/2⌋∗⌊</span>N/2<span>⌋ for example, then </span>the</a> total parameters is less than equal to N/2 * N/2 * 2 = N2/2, which is then less than N2. Since more non-zero terms are included in the covariance matrix, that means the mutual information between two latent variables has been included, so it might perform better than a pure diagonal matrix. 3.4.5 ToeplitzNorm Toeplitz matrices are another type of covariance matrix that can be utilized. We create the autoguide ToeplitzNorm. The toeplitz matrix is a matrix in which the diagonals from left to right are constant. Toeplitz matrix C with n+1 rows and n+1 columns can <a href="javascript:openDSC(727367461, 2909, '126');" onmouseover="doRollover(93);" onmouseout="undoRollover(93);" id="126" name="93" style="color:#935F32" class="#935F32"><span class="b-ref">93</span>We have<span> a0 ⎛ </span>a−1<span> C = . a−</span>n<span>+1 ⎜⎜ </span>a−n ⎝ a<span> 0 </span>a<span> 1 . . . . . . . . . . . . a−</span>n+1<span> · · · a1 · · · an−</span>1<span> . . . . . . a0 </span>a−1</a> an an−1⎞ . a1 a0 ⎟⎟ ⎠ be written as: Ci+1, j+1 = Ci, j = a j−i (3.10) where <a href="javascript:openDSC(232128294, 5, '142');" onmouseover="doRollover(109);" onmouseout="undoRollover(109);" id="142" name="109" style="color:#227967" class="#227967"><span class="b-ref">109</span>0≤i≤n-1 and 0≤j≤n-1<span>. We </span>use</a> the above equation when implementing the covariance matrix. There are two choices. If we only use the scale vector, then we enforce a−n to be equal to an. Alternatively, if we consider that the row vector differs from the column vector, then we can build a new vector that assumes another N parameter space to construct this matrix and force it to be positive definite. It takes up <a href="javascript:openDSC(666085429, 37, '84');" onmouseover="doRollover(58);" onmouseout="undoRollover(58);" id="84" name="58" style="color:#cc0066" class="#cc0066"><span class="b-ref">58</span>a maximum of<span> 3*</span>N<span> parameters, </span>where N<span> refers to </span>the number of</a> latent variables, but is computationally expensive for high-dimensional latent variables. 3.4.6 CirculantNorm A circulant matrix C is the special case of Toeplitz matrix, where C can be written as: a0 a1 · · · an−1 an ⎛an a 0 a 1 . . . C = . . . . . . . . . . an−1⎞ . a2 . . . . . . a0 a1 ⎜a1 a 2 · · · a n We create a new autoguide CirculantNorm based on the circulant matrix. By using the ⎝ a0 ⎟ ⎠ scale vector, we can generate the matrix easily. Unfortunately, making sure that the matrix is positive definite is difficult, so we use an extreme example. Specifically, we only take into account the value of a0 and a1 and disregard other terms. The matrix now looks like this: C = ⎛ 0 . a ... 0 a ... 1 ... 0 . ⎞ or,C = ⎛a1 . a ... 0 0 ... ... 0 . ⎞ a0 a1 ··· <a href="javascript:openDSC(710210796, 2022, '123');" onmouseover="doRollover(90);" onmouseout="undoRollover(90);" id="123" name="90" style="color:#CB0099" class="#CB0099"><span class="b-ref">90</span>0 . . . 0 a0 0 ··· 0 . . . a1 0 ... ... a0<span> a1 </span>0 ... ... a0<span> 0 ⎜a1 </span>0 ··· 0 0 0 ··· a</a> 1 ⎝ a0⎟ ⎠ ⎜ ⎝ a0⎟ ⎠ In order to make the matrix positive definite, we need to make sure that a0 is larger than zero and a1’s absolute value <a href="javascript:openDSC(3152471798, 3783, '30');" onmouseover="doRollover(26);" onmouseout="undoRollover(26);" id="30" name="26" style="color:#630000" class="#630000"><span class="b-ref">26</span>since the determinant<span> value </span>of<span> the </span>matrix is equal to<span> an0 + a1n in </span>the</a> left case while the answer is an0 - an1 in the right case if C ∈ Rn∗n. Regardless of n, this value should always be greater than zero. In the next round of training, if the scale vector does not satisfy the requirement, an increase in a0 or decrease in a1 will be necessary to meet the requirement (suppose a0 and a1 are all positive). 3.5 Inference Compilation Making the repeated inferences fast is critical . It is referred to as adaptive Monte Carlo method, or amortized inference [34]. Inferences about past related models are reused by humans to speed up current inferences [15]. Besides, according to the Brooks Paige et al. [49], the inverse dependency network can be equivalent to a <a href="javascript:openDSC(610784874, 37, '121');" onmouseover="doRollover(89);" onmouseout="undoRollover(89);" id="121" name="89" style="color:#227967" class="#227967"><span class="b-ref">89</span>neural network. A neural<span> network </span>can be</a> constructed for each inverse graph. As the directed graphical model is extended to universal probabilistic programs, inversing dependencies becomes increasingly difficult and impossible. Thus, the author proposes a program-specific method that ignores variable dependencies and uses a non-domain RNN model and domain-specific observation embedding to guide latent variables. LSTMs and RNNs can represent relationships between latent variables through their transfer relationship, which makes deep learning superior. Similarly, some other works focused amortized inference on one model, such as learning inference before seeing data [12, 20], which sample training data in an neural network and learning sequential Monte Carlo (SMC) proposals for fixed graphical models [49]. Inference compilation A compilation of inference is a technique that transforms an inference problem written in a universal programming language (STAN or Pyro) into a trained deep learning model written in a neural network specification language [35], such as Pytorch or Tensorflow. By feeding observational data into this neural network at test time, a probabilistic model is approximated inferenced using the original model. 3.5.1 Difference from Variational Inference Think about how we define <a href="javascript:openDSC(635881265, 37, '164');" onmouseover="doRollover(131);" onmouseout="undoRollover(131);" id="164" name="131" style="color:#006331" class="#006331"><span class="b-ref">131</span>variational inference: the goal is to find<span> a posterior in </span>the</a> approximation family Q that could minimize the divergence from our true posterior. As part of amortized inference, the given family is a set of conditional distributions of z given x instead of marginal distributions. It is thus a matter of identifying a member of the family whose divergence from the true posterior minimizes the expected divergence. KL divergence for amortized inference is <a href="javascript:openDSC(860022654, 3793, '74');" onmouseover="doRollover(52);" onmouseout="undoRollover(52);" id="74" name="52" style="color:#795AB9" class="#795AB9"><span class="b-ref">52</span>DKL(p(x|y)||q(x|y;φ</a>)) [35], which is different from the KL-divergence for variational inference in equation 2.6. Methods of learning inference differ according to the difference. Variational autoen- coders targets KL(q||p) while some methods such as reweighted wake-sleep [6, 36] and their SMC counterparts [18, 51] target KL(p||q). 3.5.2 Architecture Recurrent Neural Networks To achieve amortized inference in inference compilation, <a href="javascript:openDSC(610784874, 37, '122');" onmouseover="doRollover(89);" onmouseout="undoRollover(89);" id="122" name="89" style="color:#227967" class="#227967"><span class="b-ref">89</span>a recurrent neural network<span> model </span>is used<span> to process </span>the<span> input without regard </span>to the</a> domain [35]. Figure 3.9 illustrates the structure of a basic RNN. h⃗1 h⃗2 h⃗3 h⃗4 ... RNN RNN RNN RNN ... x⃗1 x⃗2 x⃗3 x⃗4 Figure 3.9: <a href="javascript:openDSC(2287114509, 3783, '148');" onmouseover="doRollover(115);" onmouseout="undoRollover(115);" id="148" name="115" style="color:#866712" class="#866712"><span class="b-ref">115</span>Recurrent Neural Network Particularly, the long short-term memory (LSTM</a>) [22] architecture is utilized which helps mitigate the problem that the gradients of RNN(s) tends to vanish and explode when time increases. [22] Inputs of the LSTM are the concatenation of the observed embedding, sampled embedding and one-hot encodings of current program address, instance number and proposal type of the proposal distribution [35]. Figure 2.5 shows the LSTM block where we need to pass the hidden states ht to proposal layers. Neural network architecture In particular, the <a href="javascript:openDSC(4221506181, 3796, '17');" onmouseover="doRollover(15);" onmouseout="undoRollover(15);" id="17" name="15" style="color:#866712" class="#866712"><span class="b-ref">15</span>long short term memory (LSTM) [22<span>] architecture </span>is<span> utilized </span>for<span> mitigating </span>the</a> gradient vanishing and explosion problems of a RNN [22]. We start the evaluation by computing the observe embedding fobs(x), which is domain specified. By executing a probabilistic program successively deterministically, an execution trace can be generated that looks like this: (zt,at,it)Tt=1. zt is the sampled value, at is the address of the sample and it <a href="javascript:openDSC(3446324288, 3796, '168');" onmouseover="doRollover(135);" onmouseout="undoRollover(135);" id="168" name="135" style="color:#866712" class="#866712"><span class="b-ref">135</span>is the<span> instance </span>number of<span> the sample, </span>and T is<span> a trace-dependent </span>length</a> [35]. An LSTM network architecture is automatically generated by combining an LSTM core with embedded layers, proposal layers, and a probabilistic program for training the network with <a href="javascript:openDSC(536834903, 3722, '167');" onmouseover="doRollover(134);" onmouseout="undoRollover(134);" id="167" name="134" style="color:#ce0031" class="#ce0031"><span class="b-ref">134</span>an infinite stream of<span> training </span>data<span> generated </span>from the model</a>. Figure 3.10: LSTM structure in inference compilation The details are shown in figure 3.10. The sampling embedding layer is applied to the sampled value zt−1 at the last time step. The one-hot encoding layer is also applied to address, instance, and type of address (proposal type). All of the elements constitute the LSTM input. ht is the output of LSTM. We apply proposal layers to the output ht which will lead to proposal parameters ηt. Note that the LSTM core can possibly be a stack of multiple LSTMs. After the compilation stage is finished, weights φ are trained and neural networks are specialized for the given model. Then, we use importance sampling in conjunction with the model and network parameters to obtain the posterior, which is fast and cheap when compared to compilation stage. Chapter 4 Evaluation 4.1 Environment settings The entire project requires Python 3.8.12, as well as Pyro-ppl version 1.8.1. As Pyro is a dependency of Pytorch, we must install Pytorch, where version 1.11.0 is used. VSCode, command line, and bash are used for development. In order to create training loss graphs, view latent embeddings, and generate data, we will also need to download matplotlib and seaborn, whose versions are 3.5.1 and 0.11.2 respectively. 4.2 Datasets and tasks As part of our study, we tested the benchmarking autoguides and our generated au- toguides on six datasets, including national income dataset, MNIST dataset, OSIC pulmonary fibrosis dataset, SARS-COV-2 dataset and Daily S&amp;P 500 dataset. As for the remaining one, it is created using synthetic <a href="javascript:openDSC(43999129, 3793, '156');" onmouseover="doRollover(123);" onmouseout="undoRollover(123);" id="156" name="123" style="color:blue" class="blue"><span class="b-ref">123</span>data in order to examine the<span> latent variables </span>of the<span> Gaussian Mixture </span>Models</a> (GMM). For each dataset, tasks are mentioned. 4.2.1 GMM data A number of Gaussian distribution patterns can be found in given data using Gaussian Mixture Models (GMM). The model parameters that we want to explore are mixture weights Φ, <a href="javascript:openDSC(633024452, 37, '162');" onmouseover="doRollover(129);" onmouseout="undoRollover(129);" id="162" name="129" style="color:#227967" class="#227967"><span class="b-ref">129</span>means µ and a covariance matrix Σ. The</a> following example illustrates the problem and the expected result. Suppose we have a list of data. The data consists of five elements, each of which is equal to 0, 1, 10, 11, 12. We give a Dirichlet distribution to the weights with normal distribution to the means and covariance matrix, as well as make sure that the parameter φi=1,...,K are reasonable since mixture models are sensitive and succeptible to local modes. Under the Gaussian distribution, a trained mean will be 0.5 and 11, and a trained variance might be 0.05 and 0.2. We have designed three tests based on the different lengths of data with different numbers of potential Gaussian distribution patterns. K = 2, 3 and 5 with dataset lengths of 20, 60, and 100 respectively. 28 4.2.2 National Income Dataset As part of supervised learning, linear regression is one of the most basic tasks. The Bayesian linear regression will be applied to the national income dataset adapted from this paper [40]. The purpose of exploring this dataset is to determine if the level of ruggedness of a country is related to its GDP level. Specifically, we look at non- African countries and African countries. Previously, a study stated that poor roads and terrains generally result in low income levels, but this is not always true because poor geographical conditions can elevate African countries’ GDP levels [46]. As a result, the results are positive for African countries. By looking at the original data, but also by inferring latent patterns and predicting the data, we can find out if this rule holds true for African countries. Three features have been extracted from the dataset. 4.2.3 MNIST MNIST is a large-scale dataset <a href="javascript:openDSC(288655444, 3797, '36');" onmouseover="doRollover(31);" onmouseout="undoRollover(31);" id="36" name="31" style="color:#006331" class="#006331"><span class="b-ref">31</span>comprised of 60,000 training and 10,000 test examples<span> of </span>handwritten digits<span> [13]. MNIST </span>is a</a> well-known benchmark dataset that is used mostly for <a href="javascript:openDSC(666085429, 37, '85');" onmouseover="doRollover(58);" onmouseout="undoRollover(58);" id="85" name="58" style="color:#cc0066" class="#cc0066"><span class="b-ref">58</span>computer vision<span> oriented </span>tasks such as image classification<span> [11] </span>and</a> image reconstruction [50, 42]. To determine whether autoguides can infer <a href="javascript:openDSC(872254273, 3791, '28');" onmouseover="doRollover(24);" onmouseout="undoRollover(24);" id="28" name="24" style="color:brown" class="brown"><span class="b-ref">24</span>latent variables in<span> some classical </span>deep generative models, we<span> are interested in </span>the</a> reconstruction tasks in this project. Specifically, a variational autoencoder with the structure of an encoder- decoder network is being developed. Autoguides are used for guiding the model (the decoder part) where the corresponding plate model is shown in figure 2.3. 4.2.4 OSIC Pulmonary Fibrosis From Kaggle competition, we selected OSIC Pulmonary Fibrosis Dataset [38]. Pul- monary fibrosis has no known cause or cure. We are trying to predict the severity of lung function decline in this dataset. Spirometers measure forced vital capacity (FVC). When it comes to medical applications, a model’s level of confidence can be useful. The 176 patients who were measured for FVC made an average of nine visits. Visits occurred in the interval [-12, 133] during specific weeks. The decline in lung capacity is very evident and varies widely from patient to patient. FVC measurement for each patient for each week in the interval of [-12, 133] was predicted, along with their confidence to match. In this application, we will use Bayesian hierarchical linear regression with partial pooling using parameters α and β. Even though α and β differ for each patient, the coefficients all share a similarity. The individual coefficients can be modelled by assuming they all come from the same group distribution. 4.2.5 <a href="javascript:openDSC(19300739, 3793, '172');" onmouseover="doRollover(139);" onmouseout="undoRollover(139);" id="172" name="139" style="color:#21785B" class="#21785B"><span class="b-ref">139</span>Daily S&amp;P 500<span> dataset </span>Daily S&amp;P 500</a> is the dataset that tracks the performance of 500 large companies in the United States that deal with stock exchanges. As input data, we chose the close price of the market. The model that we used is a stochastic volatility model [26], which is utilized as a mainstream market prediction model [64]. Predicting the data that matches the market’s direction is our goal. Under normal conditions, autoguide will encounter a memory overflow on training latent variables due to the large size of the dataset, which is why we have selected data within the last 100 days. The number of days is the parameter that we can adjust in the experiments. 4.2.6 SARS-COV-2 Many studies have focused on the epidemic situation of SARS-COV-2 (Covid-19) in the past two years, which is why we included it to complement the timeliness of the dataset. Based on public data collected from different PANGO lineage viral genome samples around the world over time [14], this dataset includes the relative growth rates of different SARS-CoV-2 strains . There are about 2 million sequences in total. The plate structure of the model would return a block-diagonal like posterior covariance matrix with an estimated 500,000 latent variables. Due to the high dimensions, the program would also suffer from gradient explosion. We therefore set an autoguide list, add the autoguide first, and then add a local guide to the list that blocks some latent variables. This will aid in solving gradient explosion <a href="javascript:openDSC(147331460, 3793, '40');" onmouseover="doRollover(34);" onmouseout="undoRollover(34);" id="40" name="34" style="color:#ce0031" class="#ce0031"><span class="b-ref">34</span>in a high dimensional<span> latent </span>space<span>. Our goal is </span>to</a> see if structured autoguides will improve in the large dimensional space. 4.3 Tested autoguides We have selected AutoDiagonalNormal, AutoMultivariateNormal, AutoLowRankMulti- variateNormal and AutoStructured-faithful as our baseline autoguides. PolyDiagNorm, SymmetricNorm, LowRankNorm, BlockDiagNorm, ToeplitzNorm, and CirculantNorm mentioned in 3.4 will be tested as new autoguides, as well as two inversed dependencies based methods mentioned in 3.3 including Structured-topo and Structured-min-dis. 4.4 Aims of experiments (tasks) 1. To find out whether the new autoguides can further reduce the loss, we test all those autoguides on different datasets. This is the main purpose of all experiments. In light of the fact that the results of any random seed will be similar,we are not testing random seeds. Fixed seed number is 2022. 2. Different datasets and models serve different purposes. The purpose of testing GMM data was to see approximate Gaussian patterns in the data. The income dataset was tested to determine if the bootstrap parameters confirm whether the ruggness has a reverse effect on African countries’ incomes. The MNIST dataset was used to test if autoguide could guide deep generative models. The SARS- CoV-2 dataset was used to test the inverse dependency model’s strength in the case of high dimensionality. In testing the OSIC dataset and S&amp;P 500 dataset, one goal was to expand application scenarios for autoguides, and another goal was to validate their capabilities by guiding models in latent space with relatively high dimensions. Based on standard benchmark tests, we used Pyro’s existing code to generate images of parameters, losses, and different inference patterns. 3. We will outline the possible scenarios of the new autoguides based on the data we have selected, including some advantages and disadvantages in the case of both high-dimensional and low-dimensional latent variables, as well as the impact of structured autoguides when dependencies are included. 4.5 Results GMM dataset SymmetricNorm and LowRankNorm performed the best when K equals 2, which indicates that they reached the lowest loss during the training. Nevertheless, they might suffer from a high variance problem, as shown in the table 4.1. When K is equal to 3, PolyDiagNorm and ToeplitzNorm were the best according to the loss. Structured autoguide performed the best among all autoguides when K is equal to 5. The reason why Structured-topo and Structured-min-ds have shown the same results with Structured-faithful is that in the corresponding graphical model, the parents of ”obs” are ”weight”, ”loc” and ”scale” with no potential path between each two parents. Regardless of the type of inversed model we use, the last parameter in the plate (in order) will always be the first node to be considered for adding markov blankets. Table 4.1: Testsing autoguides on GMM dataset Model <a href="javascript:openDSC(2705562323, 3722, '147');" onmouseover="doRollover(114);" onmouseout="undoRollover(114);" id="147" name="114" style="color:#ce0031" class="#ce0031"><span class="b-ref">114</span>K=2<span> WEIGHT (</span>K = 2<span>) LOC (</span>K = 2<span>) SCALE (</span>K = 2) K<span>=3 </span>K</a> =5 DiagonalNorm 72.65 0.67, 0.33 17.42, 10.27 1.57 194.77 334.02 MultivariateNorm 72.44 0.67, 0.33 17.30, 9.99 1.76 195.49 334.90 LowRankMultivariateNorm 72.09 0.53, 0.47 17.83, 9.38 1.22 195.65 331.27 PolyDiagNorm SymmetricNorm LowRankNorm BlockDiagNorm ToeplitzNorm CirculantNorm 70.68 0.67, 0.33 69.20 0.71, 0.29 69.21 0.71, 0.29 72.47 0.60, 0.40 71.02 0.63, 0.37 70.69 0.54, 0.46 19.22, 7.54 17.82, 10.04 17.90, 10.07 17.32, 7.25 17.35, 9.60 18.99, 10.52 1.44 8.46 8.39 3.13 1.63 8.30 192.48 195.37 194.25 194.82 193.24 194.10 340.17 334.43 336.00 332.77 333.78 339.18 Structured-faithful 72.09 0.68, 0.32 18.62, 9.00 1.62 194.06 330.62 Structured-topo 72.09 0.68, 0.32 18.62, 9.00 1.62 194.06 330.62 Structured-min-dis 72.09 0.68, 0.32 18.62, 9.00 1.62 194.06 330.62 Furthermore, we were interested in inferences that could be drawn from the generative model. We focused on a situation where K was equal to 3. Accordingly, different autoguides will produce different gaussian patterns. We find that CirculantNorm leads to a larger variance for each distribution, but the three other autoguides seem much more concentrated and reasonable. The reason might be that the covariance matrix for CirculantNorm is sparse as mentioned before while the covariance matrix for other three autoguides is not sparse. Also, we could take a look at the entire training records of the four autoguides listed above. This time we choose K = 5. From figure 4.6 to figure 4.9, we can find that the Strucutred and AutoNormal have shown a better level of stability during the training. ToeplitzNorm is somewhat unstable after 100 epochs, but for CirculantNorm, it is obviously unstable. To infer parameters in Gaussian mixture models, we could prefer to use ToeplitzNorm instead of CirculantNorm. In order to resolve the stability problem for CirculantNorm, we could increase the learning rate, for example 0.2 instead of 0.1, or train with more epochs, for example 1000 epochs or more. Income dataset We cared about the coefficients of this Bayesian linear regression problem, which are bias a1, the coefficient of the variable ”is cont africa” a2, the <a href="javascript:openDSC(676982372, 917, '86');" onmouseover="doRollover(59);" onmouseout="undoRollover(59);" id="86" name="59" style="color:#21785B" class="#21785B"><span class="b-ref">59</span>Figure 4.1<span>: pattern(AutoNormal) </span>Figure 4.2<span>: pattern(CirculantNorm) </span>Figure 4.3<span>: pattern(ToeplitzNorm) </span>Figure 4.4<span>: pattern(Structured) </span>Figure 4.5<span>: loss(AutoNormal) </span>Figure 4.6<span>: loss(CirculantNorm) </span>Figure 4.7<span>: loss(ToeplitzNorm) </span>Figure 4.8<span>: loss(Structured) </span>Figure 4.9</a>: Patterns and losses of four selected autoguides in the case of GMM with K = 3 and length of 60. coefficient of the variable ”ruggedness” a3, and the coefficient of their product a4. We infer the scale parameter as well. Since it’s low dimensional, it’s easy to estimate latent variables. Default learning rate is 0.15. The purpose is to determine whether terrain ruggedness correlates positively with income in African countries <a href="javascript:openDSC(3673566450, 3722, '93');" onmouseover="doRollover(63);" onmouseout="undoRollover(63);" id="93" name="63" style="color:blue" class="blue"><span class="b-ref">63</span>while the opposite is true for<span> non-African countries. </span>The<span> training </span>performance is</a> displayed for each autoguide. In comparison with all other new autoguides, ToeplitzNorm performed the best with a loss of 240.38 . It is the same Table 4.2: Testing autoguides on income dataset Model LOSS <a href="javascript:openDSC(3953052260, 3796, '157');" onmouseover="doRollover(124);" onmouseout="undoRollover(124);" id="157" name="124" style="color:brown" class="brown"><span class="b-ref">124</span>LOC(a1) LOC(a2) LOC(a3) LOC(a4) LOC</a>(SC) DiagonalNorm 243.19 9.24 -1.87 -0.06 0.41 -2.21 MultivariateNorm 243.01 9.17 -1.85 -0.18 0.34 -2.20 LowRankMultivariateNorm 239.93 9.08 -1.98 -0.24 0.27 -2.30 PolyDiagNorm SymmetricNorm LowRankNorm BlockDiagNorm ToeplitzNorm CirculantNorm 256.25 9.47 -1.67 0.37 251.32 8.57 -1.56 0.03 299.80 9.15 -1.02 -0.08 243.30 9.15 -1.81 -0.17 240.38 9.20 -1.78 -0.14 395.07 2.52 -0.68 -0.10 -0.05 -0.53 0.04 0.34 0.46 -1.03 -0.32 -0.76 -0.32 -2.30 -2.15 5.26 Structured-faithful 243.31 9.23 -1.96 -0.16 0.45 -2.23 Structured-topo 243.31 9.23 -1.96 -0.16 0.45 -2.23 Structured-min-dis 243.31 9.23 -1.96 -0.16 0.45 -2.23 inference level as LowRankMultivariateNorm, which is the baseline autoguide. Next, we can measure the density of slope in their regression lines, and also the record of training losses. The density shows no difference for LowRankNorm, so there is half the uncertainty for this distribution. It is not surprising because in the original dataset, the data seems to be similarly spread among two distributions . But for ToeplitzNorm, the data distribution of non-African countries is more concentrated. So we dig into its posterior predictive uncertainty. Figure 4.10: Slope Density(LowRank) Figure 4.11: Slope Density(Toeplitz) from from Income Data Income Data Additionally, their posterior predict ability is different. ToeplitzNorm has shown a more apparent positive slope when fitting non-African data than LowRankNorm. Therefore, although LowRankNorm has given the best training loss, its posterior predictability it not as good as ToeplitzNorm, which can infer that our new autoguides are better. In Figure 4.12: Posterior(LowRank) from Income Data Figure 4.13: Posterior(Toeplitz) from income Data terms of the stability of autoguides’ training loss, we find that overall the loss is stable except for PolyDiagNorm and SymmetricNorm. During training, the learning rate is relatively high, which makes convergence less likely. It may be necessary to adjust the learning rate to a smaller value such as 0.05 or 0.02 instead of 0.15 to better achieve a more stable training loss. The loss may also take a longer time to converge. Figure 4.14: Loss(BlockDiagNorm) from Figure 4.15: Loss(ToeplitzNorm) from Income Data Income Data MNIST On the MNIST dataset, we test the autoguides to guide the model. Specifically, the model is our decoder module in the variational autoencoder structure. First, we disregard the inference network (encoder module) and use autoguide to guide the model parameters. Then we compare the results with those that use a traditional neural network as the guide, which is a traditional non-autoguide type inference network. SymmetricNorm, LowRankNorm and CirculantNorm performed better on training loss than the baseline autoguides. In our comparison of their embeddings, we find that, despite the autoguides having a lower training loss, no significant difference can be observed between the two classes in the t-SNE visualization. Despite better performance, given the latent variables, the new autoguides cannot recover to the original data. We illustrate this by looking at the reconstructed data generated by the program. When we guide the model using the same parameter settings without autoguide, the data is not well reconstructed, but we can deduce the number from each image. When it comes to the autoguide, we can see that none of the images are clear because it is badly reconstructed. Therefore, even with the plate model shown in figure 2.3, we conclude that it is better to use a simple guide (neural network encoder) instead of an autoguide. Table 4.3: Testing autoguides on MNIST dataset Model TEST ELBO LATENT DIM HIDDEN DIM DiagonalNorm 206.35 50 100 MultivariateNorm 208.38 10 10 LowRankMultivariateNorm 206.52 20 10 PolyDiagNorm SymmetricNorm LowRankNorm BlockDiagNorm ToeplitzNorm CirculantNorm 206.37 50 100 205.89 20 10 205.90 20 10 212.85 20 10 / 20 10 205.87 10 10 Structured-topo 206.30 10 10 OSIC dataset Our new autoguides are not as well as the baseline autoguides when considering the lost on OSIC datasets. In addition, the autoguide BlockDiagNorm suffers from gradient exploding, which is a common problem in high-dimensional dataset training, even if we use the clipping Adam optimizer for training. ToeplitzNorm Figure 4.16: embedding(PolyDiag) Figure 4.17: embedding(Circulant) Figure 4.18: embedding(Symmetric) Figure 4.19: embedding(BlockDiag) Figure 4.20: Embeddings from four autoguides on MNIST Figure 4.21: No autoguide Figure 4.22: With autoguide is slow in training, and CirculantNorm is unstable in its loss. BlockDiagNorm requires a small scaled coefficient of 0.0001 multiplied by the identity matrix in order to work. To reduce a high computation time cost, ToeplitzNorm should not include matrix generation by for operation in python but instead by performing the Toeplitz function within the Scipy package. On the other hand, although training CirculantNorm was not stable, it returned the lowest initial loss, which might be regarded as a good initialization method. Observing the learned FVC for AutoNormal and SymmetricNorm, we can see that the AutoNormal learned Bayesian linear regressions well. Orange and red lines are almost in line with each other. It predicts a higher uncertainty where the data points are not Table 4.4: Testing autoguides on OSIC dataset Model TEST LOSS LR DiagonalNorm 12340.73 0.11 MultivariateNorm 13093.07 0.01 LowRankMultivariateNorm 13293.03 0.01 PolyDiagNorm SymmetricNorm LowRankNorm BlockDiagNorm ToeplitzNorm CirculantNorm 14158.62 13913.47 14720.32 / slow 14756.31 0.05 0.05 0.06 0.001 0.02 0.001 Structured-topo 15404.57 0.004 Structured-min-dis 15433.26 0.004 showing a predicted slope as shown in the first patient. However, it predicts a higher confidence for patient 2 and patient 3. When it comes to SymmetricNorm, it adequately learned Bayesian Linear Regressions, but it does not ensure a good confidence interval. As a result, there is a tradeoff between a high fitness and a small variance (confidence interval). Several autoguides follow the same pattern, so if we want to explore more concentrated patterns for new autoguides, new parameters’ initialization should be fully explored. From this, it can be concluded that it is difficult to determine whether our new method performs better than any other autoguide in all aspects. Although it might improve the loss, level up the ELBO, it might damage concentration on data patterns. SARS-COV-2 We found that in such a high dimensional dataset with Figure 4.23: FVC AutoNormal from OSIC data Figure 4.24: FVC SymmetricNorm from OSIC data structured latent variables, two methods based on inverse dependency models performed better than covariance based autoguides with a loss of 12.04. They showed a good mean average error (MAE) in the inference step. Again, BlockDiagNorm suffers from gradient explosion. Performing ToeplitzNorm is too slow because there are 538452 latent variables and 4806046 learnable parameters, which is computationally difficult as mentioned before. Table 4.5: Testing autoguides on SARS-COV-2 Model LOSS MAE(OVERALL) MAE( MASSACHUSETTS) LR DiagonalNorm 10.34 0.19 0.10 0.01 MultivariateNorm 691.6 1.33 0.58 0.005 LowRankMultivariateNorm 20.71 0.25 0.26 0.009 PolyDiagNorm SymmetricNorm LowRankNorm BlockDiagNorm ToeplitzNorm CirculantNorm 73.03 0.85 0.41 81.85 0.82 0.43 634.50 1.13 0.47 / / / slow / / 77.61 0.73 0.39 0.005 0.005 0.005 / / 0.005 Structured-topo 12.04 0.16 0.20 0.1 Structured-min-dis 12.04 0.16 0.20 0.1 Looking into the training session of structured-topo and CirculantNorm, for example, structured-topo shows a sharper gradient descent and lower loss after 1000 epochs. Other parameters also decreased significantly. We can see from the figure that the loss can be further reduced even though it is at the same level as the AutoDiagonalNorm in baseline autoguides. By setting better learning rates or optimizer’s parameters, loss can be further reduced. In general, covariance-based autoguides with the same parameters have relatively small gradients and slow convergence. As a result, we should take into consideration the structured autoguide when analyzing the dataset with high dimensional latent variables with structured model. Figure 4.25: Info for structured-topo Figure 4.26: Info for CirculantNor from from SARS-COV-2 data SARS-COV-2 datam Daily S&amp;P 500 dataset We found that the new autoguides, except PolyDiagNorm, do not show any improvement in loss. Furthermore, we found that the learned latent variables have similar ranges, except for h0. Since h0 is the initial point, we infer that if the initial position of Brownian motion can be learned in the Levy model, then the loss will be small. The loss fluctuated greatly because the new autoguides may not learn this initial point. Therefore, we can have an idea, for example, let the autoguide in a baseline learn this initial position to determine the empirical distribution, and then use the learned parameters to re-initialize the model and reduce the variance. Table 4.6: Testing autoguides on daily S&amp;P 500 dataset Model LOSS h0 rloc rskew rstability SIGMA DiagonalNorm -2.81 -0.054 ± 0.101 0.011 ± 0.004 -0.026 ± 0.013 1.722 ± 0.017 2.021 ± 0.058 MultivariateNorm -0.20 0.037 ± 0.064 0.008 ± 0.008 -0.178 ± 0.021 1.152 ± 0.0302 2.182 ± 0.068 LowRankMultivariate -0.36 0.095 ± 0.065 0.001 ± 0.007 -0.298 ± 0.022 0.930 ± 0.034 2.189 ± 0.035 PolyDiagNorm SymmetricNorm LowRankNorm BlockDiagNorm ToeplitzNorm CirculantNorm -1.10 0.005 ± 0.194 8.34 0.482 ± 0.00 19.43 0.484 ± 0.043 7.54 0.560 ± 0.036 slow / 8.90 0.560 ± 0.000 0.131 ± 0.077 -0.005 ± 0.000 0.040 ± 0.045 -0.003 ± 0.035 / -0.003 ± 0.000 -0.026 ± 0.064 -0.082 ± 0.000 -0.071 ± 0.027 -0.043 ± 0.020 / -0.043 ± 0.000 1.674 ± 0.036 1.049 ± 0.000 1.047 ± 0.023 1.082 ± 0.020 / 1.082 ± 0.000 0.835 ± 0.010 1.668 ± 0.000 1.667 ± 0.069 1.540 ± 0.051 / 1.543 ± 0.000 Structured-topo 7.96 / / / / / Structured-min-dis 7.96 / / / / / We compared the priority order of nodes when running two structured autoguides. The results obtained in the actual running process are similar, showing that different inverses can achieve similar results. AutoStructured object in Pyro has no attribute quantiles so we do not generate the latent variable distributions for AutoStructured . Below are the results of two reversing algorithms applied to the daily S&amp;P 500 dataset: Structured-topo: {’r’: 0, ’r t exponential’: 1, ’r t uniform’: 2, ’r z exponential’: 3, ’r z uniform’: 4, ’r stability’: 5, ’r skew’: 6, ’r loc’: 7, ’v dct’: 8, ’sigma’: 9, ’h 0’: 10} Structured-min-dis: {’r’: 0, ’sigma’: 1, ’r stability’: 2, ’v dct’: 3, ’r loc’: 4, ’r z expo nential’: 5, ’r t uniform’: 6, ’r z uniform’: 7, ’r t exponential’: 8, ’r skew’: 9, ’h 0’: 10} Both of the inverse dependency models will lead to a similar loss and predictability. The figures 4.25 and 4.26 show that volatility is approximately equal to the areas of log Figure 4.27: Log return CirculantNorm from S&amp;P 500 Figure 4.28: Log return SymmetricNorm from S&amp;P 500 returns in the last 100 days for CirculantNorm and SymmetricNorm. This uncertainty has been underestimated because AutoDiagonalNormal was used as an approximate guide. <a href="javascript:openDSC(2687381442, 3797, '108');" onmouseover="doRollover(77);" onmouseout="undoRollover(77);" id="108" name="77" style="color:#A85503" class="#A85503"><span class="b-ref">77</span>Hamiltonian Monte Carlo (HMC) [16<span>] or </span>No-U-Turn Sampler (NUTS</a>) [25] provide more precise uncertainty estimates. We recommend using MCMC sampling over autoguides in this case as the result is too rough even if the guide is created with the best of intentions. The gradient exploding problem also occurs when running ToeplitzNorm on this dataset with high dimensional latent variables. Chapter 5 Discussions and Conclusions 5.1 Results overview In comparison to the baseline’s four autoguides, our eight new autoguides have been tested on six datasets. It is shown that SymmetricNorm and LowRankNorm (new) are optimized on GMM dataset, and that these two also have relatively large variance problems. On income dataset, it is found that ToeplitzNorm is the best, and it is able to learn better density and slope than the basic autoguides. The new autoguide is able to reduce loss on the data of MNIST, but not as much as the loss obtained by designing with a traditional inference network. The new autoguide may not perform as well on OSIC data in terms of loss, but it has a relatively good degree of data fitting, which is achieved through the posterior. The performance of the structured autoguide on the SARS-CoV-2 dataset is on par with the baseline autoguides. In light of the above analysis, one can conclude that autoguides based on covariance matrices can be useful in models that have relatively low design dimensions and not so strong dependencies among variables. However, some autoguides based on an inverted dependency model can be used when the dimensions are relatively large and the relationships between variables are complicated. The initial autoguides, in general, can generally be improved. We also discovered that autoguide cannot be used in <a href="javascript:openDSC(680023857, 917, '165');" onmouseover="doRollover(132);" onmouseout="undoRollover(132);" id="165" name="132" style="color:#795AB9" class="#795AB9"><span class="b-ref">132</span>deep generative models. As<span> an </span>example, variational auto-encoders</a> still need to use an nn-based encoder as an inference network rather than an autoguide model. 5.2 Discussions and future works There are a lot of problems during training, such as initialization. When testing SARS- CoV-2 and OSIC datasets, the initial value for the loc and scale is relatively large, which leads to the problem of gradient explosion in some algorithms <a href="javascript:openDSC(135745519, 3793, '71');" onmouseover="doRollover(49);" onmouseout="undoRollover(49);" id="71" name="49" style="color:#227967" class="#227967"><span class="b-ref">49</span>when dealing with high<span> dimensions, so </span>it is<span> necessary </span>to<span> greatly </span>reduce the</a> initial value of loc and scale. ToeplitzNorm autoguide runs very slowly when dealing with large dimensions. It is also necessary to judge that the determinant of all submatrices is larger than zero to keep positive definite. Thus, for high-dimensional matrices, it may be necessary to 39 Chapter 5. Discussions and Conclusions use Scipy’s algorithm to expand the matrix and convert it to a positive definite matrix. Scipy does not yet support computing torch tensor with gradients, so the scale cannot be trained. We can solve this problem by adding scale to loc or by multiplying scale by the product of covariance matrices. Besides, we must compromise between mean and variance. Daily S&amp;P 500 and OSIC dataset indicate that although the new autoguide performs well in inferring mean parameters, the variances are large, which means that the confidence interval is uncertain. It is necessary to devise a method for gradually reducing the scale, leaving aside the manual adjustment method mentioned above. Baseline selection is the subject of another discussion. At present, datasets are selected based on autoguide availability, but for some datasets with hidden variables of higher dimensions, other methods may be needed to compare autoguides, such as MCMC [58], NUTS [25], and other well-performed sampling methods, rather than only baseline autoguides. Our future plans include incorporating <a href="javascript:openDSC(616812302, 37, '79');" onmouseover="doRollover(55);" onmouseout="undoRollover(55);" id="79" name="55" style="color:#866712" class="#866712"><span class="b-ref">55</span>state-of-the-art<span> inference </span>methods and<span> sampling-based </span>methods<span>. Furthermore, </span>we<span> might include </span>the</a> IC-based RNN style autoguide in the future. Also, we found that although different seeds get similar results, the more accurate method of getting report loss or accuracy still needs to be averaged by testing different seeds. This is to demonstrate that the method is robust. 5.3 Conclusions Six new autoguides based on different types of covariance matrices were implemented in this project, which are PolyDiagNorm, SymmetricNorm, LowRankNorm, BlockDiag- Norm, ToeplitzNorm, and CircularNorm. With latent-to-observed style and observed-to- latent style, we use the implemented AutoStructured-faithful and our new autoguides Structured-topo and Structured-min-dis, which are based on topological ordering of the original graph and minimum distance orderings from the observed node. Together with another three baseline autoguides AutoDiagonalNormal, AutoMultivariateNormal and AutoLowRankMultivariateNormal, we perform the guide tests on some bench- marking datasets in classical inference problems and come into the conclusions for each individual dataset. In addition, we find some general rules that covariance-based autoguides improve some aspects when latent variables are low dimensional, but inverse dependency-based autoguides improve some aspects when latent variables are high dimensional and complicated in structure. Autoguides are not suitable for inferring latent variable parameters in deep generative <a href="javascript:openDSC(757327691, 37, '140');" onmouseover="doRollover(107);" onmouseout="undoRollover(107);" id="140" name="107" style="color:#0270B6" class="#0270B6"><span class="b-ref">107</span>models, such as variational autoencoders and deep markov models. The</a> inference network should instead be an neural network based encoder (guide). Bibliography [1] Tihomir Asparouhov and Bengt Muthén. <a href="javascript:openDSC(1528957185, 3783, '104');" onmouseover="doRollover(73);" onmouseout="undoRollover(73);" id="104" name="73" style="color:#935F32" class="#935F32"><span class="b-ref">73</span>Auxiliary variables in mixture<span> mod- eling: </span>Three-step approaches using m plus. Structural equation modeling: A multidisciplinary Journal, 21(3):329–341</a>, 2014. [2] <a href="javascript:openDSC(845900166, 1, '106');" onmouseover="doRollover(75);" onmouseout="undoRollover(75);" id="106" name="75" style="color:#866712" class="#866712"><span class="b-ref">75</span>Marenglen Biba. Integrating logic and probability: Algorithmic improvements in markov logic networks. PHD, university of Bari, italy, 2009. [3</a>] Eli Bingham, Jonathan <a href="javascript:openDSC(2107601977, 3796, '32');" onmouseover="doRollover(28);" onmouseout="undoRollover(28);" id="32" name="28" style="color:#330099" class="#330099"><span class="b-ref">28</span>P Chen<span>, Martin </span>Jankowiak<span>, Fritz </span>Obermeyer<span>, Neeraj </span>Pradhan<span>, Theofanis </span>Karaletsos<span>, Rohit </span>Singh<span>, Paul </span>Szerlip<span>, Paul </span>Horsfall, and<span> Noah </span>D Goodman. Pyro: Deep universal probabilistic programming. The Journal of Machine Learning Research, 20(1):973–978, 2019<span>. [4] David </span>M Blei<span>, Alp </span>Kucukelbir, and<span> Jon </span>D McAuliffe. Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017</a>. [5] <a href="javascript:openDSC(3875844602, 3796, '9');" onmouseover="doRollover(7);" onmouseout="undoRollover(7);" id="9" name="7" style="color:#0270B6" class="#0270B6"><span class="b-ref">7</span>David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational inference: A review for statisticians. Journal of the American Statistical Association, 112(518):859–877, Apr 2017</a>. [6] <a href="javascript:openDSC(3232353002, 3797, '55');" onmouseover="doRollover(43);" onmouseout="undoRollover(43);" id="55" name="43" style="color:blue" class="blue"><span class="b-ref">43</span>Jörg Bornschein and Yoshua Bengio. Reweighted wake-sleep. arXiv preprint arXiv:1406.2751, 2014</a>. [7] <a href="javascript:openDSC(3910550734, 3796, '38');" onmouseover="doRollover(33);" onmouseout="undoRollover(33);" id="38" name="33" style="color:#935F32" class="#935F32"><span class="b-ref">33</span>Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. arXiv preprint arXiv:1509.00519, 2015<span>. [8] </span>Bob Carpenter, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. Stan: A<span> probabilistic </span>programming language. Journal of statistical software, 76(1</a>):1–32, 2017. [9] <a href="javascript:openDSC(3504035725, 3722, '45');" onmouseover="doRollover(38);" onmouseout="undoRollover(38);" id="45" name="38" style="color:#cc0066" class="#cc0066"><span class="b-ref">38</span>Mario Lezcano Casado. Compiled inference with probabilistic programming for large-scale scientific simulations<span>. PhD </span>thesis, University of Oxford, 2017</a>. [<a href="javascript:openDSC(809400068, 1, '99');" onmouseover="doRollover(68);" onmouseout="undoRollover(68);" id="99" name="68" style="color:#330099" class="#330099"><span class="b-ref">68</span>10] George Casella and Edward I George. Explaining the gibbs sampler. The American Statistician, 46(3):167–174, 1992. [11</a>] <a href="javascript:openDSC(2106679329, 3797, '21');" onmouseover="doRollover(19);" onmouseout="undoRollover(19);" id="21" name="19" style="color:#21785B" class="#21785B"><span class="b-ref">19</span>Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik. Emnist: Extending mnist to handwritten letters. In 2017 international joint conference on neural networks (IJCNN), pages 2921–2926. IEEE, 2017</a>. 41 [12] <a href="javascript:openDSC(3906171914, 3796, '34');" onmouseover="doRollover(30);" onmouseout="undoRollover(30);" id="34" name="30" style="color:#CB0099" class="#CB0099"><span class="b-ref">30</span>Peter Dayan, Geoffrey E Hinton, Radford M Neal, and Richard S Zemel. The helmholtz machine. Neural computation, 7(5):889–904, 1995</a>. [13] <a href="javascript:openDSC(2127175899, 3797, '22');" onmouseover="doRollover(20);" onmouseout="undoRollover(20);" id="22" name="20" style="color:#336699" class="#336699"><span class="b-ref">20</span>Li Deng. The mnist database of handwritten digit images for machine learning research [best of the web]. IEEE signal processing magazine, 29(6):141–142, 2012. [14</a>] <a href="javascript:openDSC(3514167287, 3797, '76');" onmouseover="doRollover(53);" onmouseout="undoRollover(53);" id="76" name="53" style="color:#935F32" class="#935F32"><span class="b-ref">53</span>Andrew Gelman, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, and Martin Modrák. Bayesian workflow. arXiv preprint arXiv:2011.01808, 2020<span>. [15] Samuel Gershman </span>and</a><a href="javascript:openDSC(539557037, 3791, '102');" onmouseover="doRollover(71);" onmouseout="undoRollover(71);" id="102" name="71" style="color:#006331" class="#006331"><span class="b-ref">71</span>Noah Goodman. Amortized inference in probabilistic reasoning. In Proceedings of the annual meeting of the cognitive science society<span>, volume </span>36, 2014</a>. [<a href="javascript:openDSC(649180516, 3796, '20');" onmouseover="doRollover(18);" onmouseout="undoRollover(18);" id="20" name="18" style="color:#cc0066" class="#cc0066"><span class="b-ref">18</span>16] Mark Girolami and Ben Calderhead. Riemann manifold langevin and hamiltonian monte carlo methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(2):123–214, 2011. [17</a>] <a href="javascript:openDSC(860022654, 3793, '75');" onmouseover="doRollover(52);" onmouseout="undoRollover(52);" id="75" name="52" style="color:#795AB9" class="#795AB9"><span class="b-ref">52</span>Noah Goodman, Vikash Mansinghka, Daniel M Roy, Keith Bonawitz, and Joshua B Tenenbaum. Church: a language for generative models. arXiv preprint arXiv:1206.3255, 2012</a>. [18] <a href="javascript:openDSC(2809094375, 3783, '128');" onmouseover="doRollover(95);" onmouseout="undoRollover(95);" id="128" name="95" style="color:#866712" class="#866712"><span class="b-ref">95</span>Shixiang Gu, Zoubin Ghahramani<span>, and </span>Richard E Turner. Neural adaptive<span> sequen- tial </span>monte carlo<span>. arXiv preprint arXiv:</span>1506.03338</a>, <a href="javascript:openDSC(1784928248, 1, '44');" onmouseover="doRollover(37);" onmouseout="undoRollover(37);" id="44" name="37" style="color:#A85503" class="#A85503"><span class="b-ref">37</span>2015. [19] Nicholas J Higham. Cholesky factorization. Wiley Interdisciplinary Reviews<span>: Computational </span>Statistics, 1(2):251–254, 2009. [20</a>] <a href="javascript:openDSC(1226152476, 3265, '1');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="1" name="1" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">1</span>Geoffrey E Hinton, Peter Dayan, Brendan J Frey, and Radford M Neal. The” wake- sleep” algorithm for unsupervised neural networks. Science, 268(5214):1158– 1161, 1995<span>. [21] </span>Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning algorithm for deep belief nets. Neural computation, 18(7):1527–1554, 2006<span>. [22] Sepp Hochreiter </span>and</a><a href="javascript:openDSC(2167618554, 3797, '23');" onmouseover="doRollover(21);" onmouseout="undoRollover(21);" id="23" name="21" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">21</span>Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997. [23</a>] <a href="javascript:openDSC(983584563, 3793, '4');" onmouseover="doRollover(3);" onmouseout="undoRollover(3);" id="4" name="3" style="color:blue" class="blue"><span class="b-ref">3</span>Matthew D Hoffman and David M Blei. Structured stochastic variational inference. In Artificial Intelligence and Statistics, pages 361–369, 2015<span>. [24] </span>Matthew D Hoffman, David M Blei, Chong Wang, and John Paisley. Stochastic variational inference. Journal of Machine Learning Research</a>, 2013. [25] <a href="javascript:openDSC(1712975326, 3797, '7');" onmouseover="doRollover(5);" onmouseout="undoRollover(5);" id="7" name="5" style="color:#B64B01" class="#B64B01"><span class="b-ref">5</span>Matthew D Hoffman, Andrew Gelman, et al. The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo. J. Mach. Learn. Res., 15(1):1593– 1623, 2014</a>. [26] <a href="javascript:openDSC(1657348315, 3788, '90');" onmouseover="doRollover(61);" onmouseout="undoRollover(61);" id="90" name="61" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">61</span>Eric Jacquier, Nicholas G Polson, and Peter E Rossi. Bayesian analysis of stochas- tic volatility models. Journal of Business &amp; Economic Statistics, 20(1):69–87, 2002</a>. [27] <a href="javascript:openDSC(3906171914, 3796, '35');" onmouseover="doRollover(30);" onmouseout="undoRollover(30);" id="35" name="30" style="color:#CB0099" class="#CB0099"><span class="b-ref">30</span>Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016<span>. [28] Richard Arnold </span>Johnson<span>, Dean W Wichern, </span>et al</a>. <a href="javascript:openDSC(671190883, 2, '141');" onmouseover="doRollover(108);" onmouseout="undoRollover(108);" id="141" name="108" style="color:#330099" class="#330099"><span class="b-ref">108</span>Applied multivariate statistical analysis, volume 6. Pearson London, UK:, 2014</a>. [29] <a href="javascript:openDSC(2411566379, 3796, '57');" onmouseover="doRollover(44);" onmouseout="undoRollover(44);" id="57" name="44" style="color:brown" class="brown"><span class="b-ref">44</span>Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013<span>. [30] </span>Durk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling. Improved variational inference with inverse autoregressive flow. Advances in neural information processing systems, 29</a>, <a href="javascript:openDSC(1561983947, 1, '105');" onmouseover="doRollover(74);" onmouseout="undoRollover(74);" id="105" name="74" style="color:#ce0031" class="#ce0031"><span class="b-ref">74</span>2016. [31] Thomas N Kipf and Max Welling. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308, 2016. [32</a>] <a href="javascript:openDSC(658131747, 3796, '18');" onmouseover="doRollover(16);" onmouseout="undoRollover(16);" id="18" name="16" style="color:#63009c" class="#63009c"><span class="b-ref">16</span>Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009<span>. [33] </span>Alp Kucukelbir, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and David M Blei. Automatic differentiation variational inference. The Journal of Machine Learning Research, 18(1):430–474, 2017</a>. [34] Tuan Anh Le. Amortized inference and model learning for probabilistic program- ming. PhD thesis, University of Oxford, 2019. [35] <a href="javascript:openDSC(3201450443, 3265, '29');" onmouseover="doRollover(25);" onmouseout="undoRollover(25);" id="29" name="25" style="color:#B64B01" class="#B64B01"><span class="b-ref">25</span>Tuan Anh Le, Atilim Gunes Baydin, and Frank Wood. Inference compilation and universal probabilistic programming. In Artificial Intelligence and Statistics, pages 1338–1348</a>. PMLR, 2017. [36] <a href="javascript:openDSC(1839055255, 3796, '33');" onmouseover="doRollover(29);" onmouseout="undoRollover(29);" id="33" name="29" style="color:#227967" class="#227967"><span class="b-ref">29</span>Tuan Anh Le, Adam R Kosiorek, N Siddharth, Yee Whye Teh, and Frank Wood. Revisiting reweighted wake-sleep for models with stochastic control flow. In Uncertainty in Artificial Intelligence, pages 1039–1049. PMLR, 2020</a>. [37] <a href="javascript:openDSC(286620973, 3793, '2');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="2" name="2" style="color:#287B28" class="#287B28"><span class="b-ref">2</span>Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribu- tion: A continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016</a>. [38] <a href="javascript:openDSC(744536340, 37, '137');" onmouseover="doRollover(104);" onmouseout="undoRollover(104);" id="137" name="104" style="color:brown" class="brown"><span class="b-ref">104</span>Sampurna Mandal, Valentina E Balas, Rabindra Nath Shaw, and Ankush Ghosh</a>. Prediction analysis of idiopathic pulmonary fibrosis progression from osic dataset. In 2020 IEEE International conference on computing, power and communication technologies (GUCON), pages 861–865. IEEE, 2020. [39] <a href="javascript:openDSC(3504035725, 3722, '46');" onmouseover="doRollover(38);" onmouseout="undoRollover(38);" id="46" name="38" style="color:#cc0066" class="#cc0066"><span class="b-ref">38</span>Vikash Mansinghka, Richard Tibbetts, Jay Baxter, Pat Shafto, and Baxter Eaves. Bayesdb: A probabilistic programming system for querying the probable<span> implica- tions </span>of data. arXiv preprint arXiv:1512.05006, 2015</a>. [40] Richard <a href="javascript:openDSC(585977498, 37, '134');" onmouseover="doRollover(101);" onmouseout="undoRollover(101);" id="134" name="101" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">101</span>McElreath. rethinking: Statistical rethinking book package. R package version, 1, 2016</a>. [41] <a href="javascript:openDSC(3232353002, 3797, '56');" onmouseover="doRollover(43);" onmouseout="undoRollover(43);" id="56" name="43" style="color:blue" class="blue"><span class="b-ref">43</span>Brian Milch, Bhaskara Marthi, and Stuart Russell. Blog: Relational modeling with unknown objects. In ICML 2004 workshop on statistical relational learning and its connections to other fields, pages 67–73, 2004</a>. [42] <a href="javascript:openDSC(757017271, 37, '81');" onmouseover="doRollover(57);" onmouseout="undoRollover(57);" id="81" name="57" style="color:#A85503" class="#A85503"><span class="b-ref">57</span>Smitha Milli, Ludwig Schmidt, Anca D Dragan, and Moritz Hardt. Model recon- struction from model explanations. In Proceedings of the Conference on Fairness, Accountability, and Transparency, pages 1–9, 2019</a>. [43] <a href="javascript:openDSC(1371385889, 3788, '25');" onmouseover="doRollover(23);" onmouseout="undoRollover(23);" id="25" name="23" style="color:blue" class="blue"><span class="b-ref">23</span>T Minka<span>, JM </span>Winn<span>, JP </span>Guiver, Y Zaykov, D Fabian, and J Bronskill. Infer .net 2.7.(2018). URL http://research. microsoft. com/infernet. Microsoft Research Cambridge, 1<span>, 2018. [44] Lawrence </span>M Murray</a><a href="javascript:openDSC(286588393, 3793, '12');" onmouseover="doRollover(10);" onmouseout="undoRollover(10);" id="12" name="10" style="color:#CB0099" class="#CB0099"><span class="b-ref">10</span>and Thomas B Schön<span>. Automated </span>learning with a<span> prob- abilistic </span>programming language: Birch. Annual Reviews in Control, 46:29–43, 2018</a>. [45] <a href="javascript:openDSC(286620973, 3793, '3');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="3" name="2" style="color:#287B28" class="#287B28"><span class="b-ref">2</span>Christian Naesseth, Francisco Ruiz, Scott Linderman, and David Blei. Repa- rameterization gradients through acceptance-rejection sampling algorithms. In Artificial Intelligence and Statistics, pages 489–498</a>. PMLR, 2017. [46] <a href="javascript:openDSC(4013718036, 2209, '95');" onmouseover="doRollover(65);" onmouseout="undoRollover(65);" id="95" name="65" style="color:#B64B01" class="#B64B01"><span class="b-ref">65</span>Nathan Nunn and Diego Puga. Ruggedness: The blessing of bad geography in africa. Review of Economics and Statistics, 94(1):20–36, 2012</a>. [47] <a href="javascript:openDSC(1780719351, 3796, '158');" onmouseover="doRollover(125);" onmouseout="undoRollover(125);" id="158" name="125" style="color:#B64B01" class="#B64B01"><span class="b-ref">125</span>David J Olive. Statistical theory and inference. Springer, 2014</a>. [48] Brooks <a href="javascript:openDSC(410866370, 3798, '11');" onmouseover="doRollover(9);" onmouseout="undoRollover(9);" id="11" name="9" style="color:#227967" class="#227967"><span class="b-ref">9</span>Paige and<span> Frank </span>Wood. A compilation target for probabilistic programming languages. In International Conference on Machine Learning, pages 1935–1943. PMLR, 2014. [49</a>] <a href="javascript:openDSC(3550983567, 3796, '47');" onmouseover="doRollover(39);" onmouseout="undoRollover(39);" id="47" name="39" style="color:#21785B" class="#21785B"><span class="b-ref">39</span>Brooks Paige and Frank Wood. Inference networks for sequential monte carlo in graphical models. In International Conference on Machine Learning, pages 3040–3049</a>. PMLR, 2016. [50] <a href="javascript:openDSC(2764316612, 3791, '110');" onmouseover="doRollover(79);" onmouseout="undoRollover(79);" id="110" name="79" style="color:#21785B" class="#21785B"><span class="b-ref">79</span>Zhimeng Pan, Brian Rodriguez, and Rajesh Menon. Machine-learning enables<span> im- age </span>reconstruction and classification in a<span> “see-through” </span>camera. OSA Continuum, 3</a>(3):401–409, 2020. [51] <a href="javascript:openDSC(286680937, 3793, '10');" onmouseover="doRollover(8);" onmouseout="undoRollover(8);" id="10" name="8" style="color:#330099" class="#330099"><span class="b-ref">8</span>Yura N Perov, Tuan Anh Le, and Frank Wood. Data-driven sequential monte carlo in probabilistic programming. arXiv preprint arXiv:1512.04387, 2015</a>. [52] <a href="javascript:openDSC(2171387143, 1, '73');" onmouseover="doRollover(51);" onmouseout="undoRollover(51);" id="73" name="51" style="color:#006331" class="#006331"><span class="b-ref">51</span>Du Phan, Neeraj Pradhan, and Martin Jankowiak. Composable effects for<span> flex- ible </span>and accelerated probabilistic programming in numpyro. arXiv preprint arXiv:1912.11554, 2019<span>. [53] </span>Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference</a>. <a href="javascript:openDSC(830373546, 3796, '143');" onmouseover="doRollover(110);" onmouseout="undoRollover(110);" id="143" name="110" style="color:#CB0099" class="#CB0099"><span class="b-ref">110</span>In Artificial intelligence and statistics, pages 814–822. PMLR, 2014</a>. [54] <a href="javascript:openDSC(3867946762, 3791, '113');" onmouseover="doRollover(82);" onmouseout="undoRollover(82);" id="113" name="82" style="color:#287B28" class="#287B28"><span class="b-ref">82</span>Rajesh Ranganath, Dustin Tran, Jaan Altosaar, and David Blei. Operator varia- tional inference<span>. Advances </span>in Neural Information Processing Systems</a>, 29, 2016. [55] <a href="javascript:openDSC(542960544, 3793, '5');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="5" name="4" style="color:brown" class="brown"><span class="b-ref">4</span>Rajesh Ranganath, Dustin Tran, and David Blei. Hierarchical variational models. In<span> International </span>Conference on Machine Learning, pages 324–333. PMLR, 2016</a>. [56] <a href="javascript:openDSC(759187030, 917, '94');" onmouseover="doRollover(64);" onmouseout="undoRollover(64);" id="94" name="64" style="color:brown" class="brown"><span class="b-ref">64</span>Douglas A Reynolds. Gaussian mixture models. Encyclopedia of biometrics, 741:659–663, 2009<span>. [57] </span>Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows</a>. <a href="javascript:openDSC(542960544, 3793, '6');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="6" name="4" style="color:brown" class="brown"><span class="b-ref">4</span>In International conference on machine learning, pages 1530–1538. PMLR, 2015. [58</a>] <a href="javascript:openDSC(744222689, 917, '77');" onmouseover="doRollover(54);" onmouseout="undoRollover(54);" id="77" name="54" style="color:#ce0031" class="#ce0031"><span class="b-ref">54</span>Christian Robert and George Casella. A short history of markov chain monte carlo: Subjective recollections from incomplete data. Statistical Science, 26(1):102–115, 2011<span>. [59] </span>Christian P Robert and George Casella</a>. <a href="javascript:openDSC(925749029, 3793, '13');" onmouseover="doRollover(11);" onmouseout="undoRollover(11);" id="13" name="11" style="color:#006331" class="#006331"><span class="b-ref">11</span>The metropolis—hastings algorithm. In Monte Carlo statistical methods, pages 231–283. Springer, 1999</a>. [60] Paul <a href="javascript:openDSC(2841806552, 3783, '131');" onmouseover="doRollover(98);" onmouseout="undoRollover(98);" id="131" name="98" style="color:#cc0066" class="#cc0066"><span class="b-ref">98</span>Rozin. The process of moralization. Psychological science, 10(3):218–221, 1999</a>. [61] <a href="javascript:openDSC(2916797636, 3797, '103');" onmouseover="doRollover(72);" onmouseout="undoRollover(72);" id="103" name="72" style="color:#795AB9" class="#795AB9"><span class="b-ref">72</span>John Salvatier, Thomas V Wiecki, and Christopher Fonnesbeck. Probabilistic programming in python using pymc3. PeerJ Computer Science, 2:e55, 2016</a>. [62] <a href="javascript:openDSC(286599452, 3793, '15');" onmouseover="doRollover(13);" onmouseout="undoRollover(13);" id="15" name="13" style="color:#935F32" class="#935F32"><span class="b-ref">13</span>Narayanaswamy Siddharth, Brooks Paige, Jan-Willem Van de Meent, Alban</a> Desmaison, Noah D Goodman, Pushmeet Kohli, Frank Wood, and Philip HS Torr. Learning disentangled representations with semi-supervised deep generative models. arXiv preprint arXiv:1706.00400, 2017. [63] <a href="javascript:openDSC(3813521985, 3796, '120');" onmouseover="doRollover(88);" onmouseout="undoRollover(88);" id="120" name="88" style="color:#330099" class="#330099"><span class="b-ref">88</span>Andreas Stuhlmüller, Jacob Taylor, and Noah Goodman. Learning stochastic inverses<span>. Advances </span>in neural information processing systems, 26</a>, 2013. [64] <a href="javascript:openDSC(655182043, 772, '114');" onmouseover="doRollover(83);" onmouseout="undoRollover(83);" id="114" name="83" style="color:blue" class="blue"><span class="b-ref">83</span>Stephen J Taylor. Modeling stochastic volatility: A review and comparative study. Mathematical finance, 4(2):183–204, 1994</a>. [65] <a href="javascript:openDSC(649179853, 3796, '19');" onmouseover="doRollover(17);" onmouseout="undoRollover(17);" id="19" name="17" style="color:#A85503" class="#A85503"><span class="b-ref">17</span>Dustin Tran, David Blei, and Edo M Airoldi. Copula variational inference. In Advances in Neural Information Processing Systems, pages 3564–3572, 2015<span>. [66] </span>Dustin Tran, Rajesh Ranganath, and David M Blei</a>. <a href="javascript:openDSC(146405453, 3793, '14');" onmouseover="doRollover(12);" onmouseout="undoRollover(12);" id="14" name="12" style="color:#795AB9" class="#795AB9"><span class="b-ref">12</span>The variational gaussian process. arXiv preprint arXiv:1511.06499, 2015</a>. [67] <a href="javascript:openDSC(645707965, 917, '96');" onmouseover="doRollover(66);" onmouseout="undoRollover(66);" id="96" name="66" style="color:#630000" class="#630000"><span class="b-ref">66</span>Paul Tseng and Sangwoon Yun. A coordinate gradient descent method for<span> non- smooth </span>separable minimization. Mathematical Programming, 117(1):387–423, 2009<span>. [68] Jan-Willem </span>van</a><a href="javascript:openDSC(983539242, 3793, '61');" onmouseover="doRollover(46);" onmouseout="undoRollover(46);" id="61" name="46" style="color:#630000" class="#630000"><span class="b-ref">46</span>de Meent, Brooks Paige, Hongseok Yang, and Frank Wood. An introduction to probabilistic programming</a>, 2021. [69] <a href="javascript:openDSC(286740857, 3793, '8');" onmouseover="doRollover(6);" onmouseout="undoRollover(6);" id="8" name="6" style="color:#630000" class="#630000"><span class="b-ref">6</span>Stefan Webb, Adam Golinski, Rob Zinkov, Tom Rainforth, Yee Whye Teh, Frank Wood<span>, et al. </span>Faithful inversion of generative models for effective amortized inference<span>. Advances </span>in Neural Information Processing Systems</a>, 31, 2018. [70] <a href="javascript:openDSC(3550983567, 3796, '48');" onmouseover="doRollover(39);" onmouseout="undoRollover(39);" id="48" name="39" style="color:#21785B" class="#21785B"><span class="b-ref">39</span>Frank Wood, Jan Willem Meent, and Vikash Mansinghka. A new approach to probabilistic programming inference. In Artificial Intelligence and Statistics, pages 1024–1032</a>. PMLR, 2014. [71] <a href="javascript:openDSC(2744161809, 3796, '100');" onmouseover="doRollover(69);" onmouseout="undoRollover(69);" id="100" name="69" style="color:#227967" class="#227967"><span class="b-ref">69</span>Mike Wu, Kristy Choi, Noah Goodman<span>, and </span>Stefano Ermon. Meta-amortized variational inference and learning. In<span> Proceedings of the </span>AAAI Conference on Artificial Intelligence</a>, volume 34, pages 6404–6412, 2020. Appendix A Others A.1 Code implementations This github repository contains more results and the full <a href="javascript:openDSC(676980145, 917, '179');" onmouseover="doRollover(146);" onmouseout="undoRollover(146);" id="179" name="146" style="color:#630000" class="#630000"><span class="b-ref">146</span>implementation of the<span> code: </span>https://github.com</a>/JIAQING-XIE/advi_nips. The dataset and plotting imple- mentation were adapted from http://github.com/pyro-ppl/pyro. 46 2 <a href="javascript:openDSC(643312618, 2, '72');" onmouseover="doRollover(50);" onmouseout="undoRollover(50);" id="72" name="50" style="color:#CB0099" class="#CB0099"><span class="b-ref">50</span>Chapter 2. Background<span> 4 </span>Chapter 2. Background<span> 5 </span>Chapter 2. Background<span> 6 </span>Chapter 2. Background<span> 7 </span>Chapter 2. Background<span> 8 </span>Chapter 2. Background<span> 9 </span>Chapter 2. Background<span> 10 </span>Chapter 2. Background<span> 11 </span>Chapter 2. Background<span> 12 </span>Chapter 2. Background<span> 13 </span>Chapter 3<span>. ADVI </span>and</a> potential improvements <a href="javascript:openDSC(25838720, 2, '41');" onmouseover="doRollover(35);" onmouseout="undoRollover(35);" id="41" name="35" style="color:#866712" class="#866712"><span class="b-ref">35</span>15 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>16 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>17 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>18 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>19 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>20 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>21 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>22 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>23 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>24 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>25 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>26 Chapter 3<span>. ADVI </span>and<span> potential improvements </span>27 Chapter</a><a href="javascript:openDSC(89494272, 2, '66');" onmouseover="doRollover(48);" onmouseout="undoRollover(48);" id="66" name="48" style="color:#330099" class="#330099"><span class="b-ref">48</span>4. Evaluation 29 Chapter 4. Evaluation 30 Chapter 4. Evaluation 31 Chapter 4. Evaluation 32 Chapter 4. Evaluation 33 Chapter 4. Evaluation 34 Chapter 4. Evaluation 35 Chapter 4. Evaluation 36 Chapter 4. Evaluation 37 Chapter 4. Evaluation 38</a><a href="javascript:openDSC(1556551535, 3796, '154');" onmouseover="doRollover(121);" onmouseout="undoRollover(121);" id="154" name="121" style="color:#D10A0A" class="#D10A0A"><span class="b-ref">121</span>40 Bibliography 42 Bibliography 43 Bibliography 44 Bibliography 45</a>
</div>

</body>
</html>

